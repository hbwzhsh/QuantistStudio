{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning PyTorch with Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _*_ coding:utf-8 _*_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wram-up:numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 30910016.9561\n",
      "1 29023249.0633\n",
      "2 29859669.9994\n",
      "3 28918449.5198\n",
      "4 24254114.455\n",
      "5 16984801.3829\n",
      "6 10260893.5478\n",
      "7 5717262.88578\n",
      "8 3211799.60431\n",
      "9 1936485.33738\n",
      "10 1289074.20481\n",
      "11 940085.582814\n",
      "12 733856.554971\n",
      "13 598862.02006\n",
      "14 502190.10009\n",
      "15 428193.249209\n",
      "16 369144.06963\n",
      "17 320674.843577\n",
      "18 280211.289242\n",
      "19 245987.843579\n",
      "20 216785.672077\n",
      "21 191696.54653\n",
      "22 170045.065357\n",
      "23 151299.883553\n",
      "24 134989.027068\n",
      "25 120726.641694\n",
      "26 108215.204733\n",
      "27 97203.5912197\n",
      "28 87489.9164437\n",
      "29 78896.9815566\n",
      "30 71276.4725435\n",
      "31 64503.801681\n",
      "32 58466.02794\n",
      "33 53073.385565\n",
      "34 48249.0334096\n",
      "35 43925.2496962\n",
      "36 40041.6551231\n",
      "37 36547.8325381\n",
      "38 33402.5477855\n",
      "39 30564.8420252\n",
      "40 27998.6825\n",
      "41 25675.7631602\n",
      "42 23569.794126\n",
      "43 21659.2891779\n",
      "44 19922.8410055\n",
      "45 18342.546764\n",
      "46 16903.4456046\n",
      "47 15590.5502256\n",
      "48 14391.5715037\n",
      "49 13295.6578678\n",
      "50 12293.9912761\n",
      "51 11376.8291251\n",
      "52 10535.7974353\n",
      "53 9764.06168479\n",
      "54 9055.64622978\n",
      "55 8404.03218965\n",
      "56 7804.44860756\n",
      "57 7252.32698873\n",
      "58 6743.48826604\n",
      "59 6274.13849353\n",
      "60 5840.77283946\n",
      "61 5440.53173381\n",
      "62 5070.42857857\n",
      "63 4728.22321352\n",
      "64 4411.31956667\n",
      "65 4118.32671384\n",
      "66 3846.66174159\n",
      "67 3594.67486447\n",
      "68 3360.71096137\n",
      "69 3143.38479421\n",
      "70 2941.26754331\n",
      "71 2753.324378\n",
      "72 2578.48810986\n",
      "73 2415.7290799\n",
      "74 2264.09818412\n",
      "75 2122.72514796\n",
      "76 1990.88455123\n",
      "77 1867.93386395\n",
      "78 1753.19003295\n",
      "79 1645.99855779\n",
      "80 1545.82732779\n",
      "81 1452.21140927\n",
      "82 1364.65639498\n",
      "83 1282.77698187\n",
      "84 1206.16802958\n",
      "85 1134.43335345\n",
      "86 1067.24576927\n",
      "87 1004.31421257\n",
      "88 945.316092492\n",
      "89 890.01346572\n",
      "90 838.140030226\n",
      "91 789.473459758\n",
      "92 743.798902304\n",
      "93 700.926093833\n",
      "94 660.679203301\n",
      "95 622.852543985\n",
      "96 587.314569836\n",
      "97 553.918290066\n",
      "98 522.536782891\n",
      "99 493.005502242\n",
      "100 465.23268727\n",
      "101 439.102130842\n",
      "102 414.510698757\n",
      "103 391.346207524\n",
      "104 369.532833715\n",
      "105 349.000308877\n",
      "106 329.659838923\n",
      "107 311.433481079\n",
      "108 294.260975335\n",
      "109 278.07616998\n",
      "110 262.817652425\n",
      "111 248.43002904\n",
      "112 234.863072556\n",
      "113 222.06861212\n",
      "114 209.996906045\n",
      "115 198.603515406\n",
      "116 187.85351778\n",
      "117 177.706695291\n",
      "118 168.126105661\n",
      "119 159.081929433\n",
      "120 150.544457336\n",
      "121 142.47925475\n",
      "122 134.857578507\n",
      "123 127.657103153\n",
      "124 120.855001026\n",
      "125 114.425152247\n",
      "126 108.347804344\n",
      "127 102.603692761\n",
      "128 97.1752032265\n",
      "129 92.0405377617\n",
      "130 87.185173371\n",
      "131 82.5932045012\n",
      "132 78.2496407931\n",
      "133 74.1408133583\n",
      "134 70.2538271398\n",
      "135 66.5764858093\n",
      "136 63.0959052567\n",
      "137 59.8019329362\n",
      "138 56.6838998555\n",
      "139 53.7327114135\n",
      "140 50.9391850172\n",
      "141 48.2944273686\n",
      "142 45.7900031868\n",
      "143 43.4184949778\n",
      "144 41.1724271039\n",
      "145 39.045601409\n",
      "146 37.0310407293\n",
      "147 35.1224019118\n",
      "148 33.3146185122\n",
      "149 31.6016856407\n",
      "150 29.9782684359\n",
      "151 28.440014081\n",
      "152 26.9822579245\n",
      "153 25.600653405\n",
      "154 24.2917351234\n",
      "155 23.050568076\n",
      "156 21.8739123294\n",
      "157 20.7587699462\n",
      "158 19.7015669544\n",
      "159 18.6991942687\n",
      "160 17.7490743853\n",
      "161 16.8476420085\n",
      "162 15.992849212\n",
      "163 15.1823405592\n",
      "164 14.4134247855\n",
      "165 13.6841847117\n",
      "166 12.9925770464\n",
      "167 12.3363607404\n",
      "168 11.7138407253\n",
      "169 11.1231810778\n",
      "170 10.5628020354\n",
      "171 10.0311287609\n",
      "172 9.52662075463\n",
      "173 9.04783849458\n",
      "174 8.59341258288\n",
      "175 8.16219569018\n",
      "176 7.75290916984\n",
      "177 7.36459626325\n",
      "178 6.99588719287\n",
      "179 6.64597348397\n",
      "180 6.31368948436\n",
      "181 5.99822290925\n",
      "182 5.69884477489\n",
      "183 5.41453445453\n",
      "184 5.14458541431\n",
      "185 4.88826480707\n",
      "186 4.64487067454\n",
      "187 4.41377846573\n",
      "188 4.19436188001\n",
      "189 3.98595542325\n",
      "190 3.78801202777\n",
      "191 3.60003857781\n",
      "192 3.4214758955\n",
      "193 3.25194105559\n",
      "194 3.09083021359\n",
      "195 2.93781141841\n",
      "196 2.79244266207\n",
      "197 2.65435392336\n",
      "198 2.52320544516\n",
      "199 2.3985875294\n",
      "200 2.28017530538\n",
      "201 2.16767577425\n",
      "202 2.06077603628\n",
      "203 1.959238453\n",
      "204 1.86273215382\n",
      "205 1.77102517457\n",
      "206 1.68387364789\n",
      "207 1.60105757552\n",
      "208 1.52237439626\n",
      "209 1.44758490298\n",
      "210 1.37649809368\n",
      "211 1.30894041335\n",
      "212 1.244725111\n",
      "213 1.18371161696\n",
      "214 1.1256970522\n",
      "215 1.07055588805\n",
      "216 1.01814255642\n",
      "217 0.968313631511\n",
      "218 0.920960938087\n",
      "219 0.875926019888\n",
      "220 0.833115375805\n",
      "221 0.792413111191\n",
      "222 0.753722846772\n",
      "223 0.716943913494\n",
      "224 0.681963454908\n",
      "225 0.648705914383\n",
      "226 0.617083196872\n",
      "227 0.587016368031\n",
      "228 0.558431213998\n",
      "229 0.531242562911\n",
      "230 0.505386674703\n",
      "231 0.480800276111\n",
      "232 0.457423773901\n",
      "233 0.435191305196\n",
      "234 0.414045895249\n",
      "235 0.393935295054\n",
      "236 0.374807342568\n",
      "237 0.356620820595\n",
      "238 0.339321437743\n",
      "239 0.322868989607\n",
      "240 0.307216709475\n",
      "241 0.29232841149\n",
      "242 0.278171898906\n",
      "243 0.264699764338\n",
      "244 0.251884745521\n",
      "245 0.239694605919\n",
      "246 0.228100078847\n",
      "247 0.217071483444\n",
      "248 0.206577110089\n",
      "249 0.196593263308\n",
      "250 0.187095014916\n",
      "251 0.17806125479\n",
      "252 0.169464876219\n",
      "253 0.161285370855\n",
      "254 0.15350302801\n",
      "255 0.146099257315\n",
      "256 0.139056732918\n",
      "257 0.132353325506\n",
      "258 0.125975205314\n",
      "259 0.119906394317\n",
      "260 0.114132913362\n",
      "261 0.1086393182\n",
      "262 0.103410737293\n",
      "263 0.098434845234\n",
      "264 0.0936996537999\n",
      "265 0.0891955433167\n",
      "266 0.0849072314964\n",
      "267 0.0808263577863\n",
      "268 0.0769427207136\n",
      "269 0.0732473299662\n",
      "270 0.0697305661076\n",
      "271 0.0663829602417\n",
      "272 0.0631968050634\n",
      "273 0.06016439361\n",
      "274 0.0572794286494\n",
      "275 0.0545326176824\n",
      "276 0.0519179841643\n",
      "277 0.0494294410694\n",
      "278 0.0470613193813\n",
      "279 0.0448070902794\n",
      "280 0.0426609702091\n",
      "281 0.040618180116\n",
      "282 0.0386739553535\n",
      "283 0.0368238058987\n",
      "284 0.0350618383503\n",
      "285 0.0333845844436\n",
      "286 0.0317879309965\n",
      "287 0.0302683575483\n",
      "288 0.0288217090267\n",
      "289 0.0274442732417\n",
      "290 0.0261330238774\n",
      "291 0.0248847399979\n",
      "292 0.0236967146957\n",
      "293 0.0225652554089\n",
      "294 0.0214880621732\n",
      "295 0.0204625350558\n",
      "296 0.0194864057416\n",
      "297 0.0185568893756\n",
      "298 0.0176718603809\n",
      "299 0.0168291965038\n",
      "300 0.0160269496411\n",
      "301 0.0152632402846\n",
      "302 0.014535974908\n",
      "303 0.0138434764083\n",
      "304 0.0131840363059\n",
      "305 0.0125563966742\n",
      "306 0.011958567098\n",
      "307 0.0113892687642\n",
      "308 0.0108471794694\n",
      "309 0.0103311181343\n",
      "310 0.00983968219309\n",
      "311 0.00937162575629\n",
      "312 0.00892592838967\n",
      "313 0.00850153776617\n",
      "314 0.00809750331299\n",
      "315 0.00771261501717\n",
      "316 0.00734610181978\n",
      "317 0.00699706097423\n",
      "318 0.00666476410012\n",
      "319 0.00634824724883\n",
      "320 0.00604679288267\n",
      "321 0.00575973890219\n",
      "322 0.00548638903121\n",
      "323 0.00522606197704\n",
      "324 0.00497807079786\n",
      "325 0.00474188528576\n",
      "326 0.00451695326942\n",
      "327 0.00430280423044\n",
      "328 0.0040987622355\n",
      "329 0.00390442597787\n",
      "330 0.00371934313646\n",
      "331 0.00354310891038\n",
      "332 0.0033752251355\n",
      "333 0.00321530345849\n",
      "334 0.00306298595204\n",
      "335 0.0029179287505\n",
      "336 0.00277977689359\n",
      "337 0.00264815491924\n",
      "338 0.00252278474547\n",
      "339 0.00240338778161\n",
      "340 0.00228969507207\n",
      "341 0.0021813464975\n",
      "342 0.00207814018876\n",
      "343 0.00197983170306\n",
      "344 0.00188621275577\n",
      "345 0.001797024907\n",
      "346 0.00171205277714\n",
      "347 0.00163111172642\n",
      "348 0.00155401923026\n",
      "349 0.00148059268958\n",
      "350 0.00141062475448\n",
      "351 0.00134397313817\n",
      "352 0.0012804792406\n",
      "353 0.00122001924449\n",
      "354 0.00116239875511\n",
      "355 0.0011075063507\n",
      "356 0.00105521737284\n",
      "357 0.00100542125593\n",
      "358 0.000957968770885\n",
      "359 0.000912754999304\n",
      "360 0.000869682235607\n",
      "361 0.000828654844605\n",
      "362 0.000789569786033\n",
      "363 0.000752324460298\n",
      "364 0.000716841269319\n",
      "365 0.000683036519572\n",
      "366 0.000650841238461\n",
      "367 0.000620156028296\n",
      "368 0.000590921693686\n",
      "369 0.000563068336427\n",
      "370 0.000536539153697\n",
      "371 0.000511258955027\n",
      "372 0.000487169862653\n",
      "373 0.000464220486972\n",
      "374 0.000442358158166\n",
      "375 0.000421528304436\n",
      "376 0.000401676718501\n",
      "377 0.000382763010474\n",
      "378 0.000364742227972\n",
      "379 0.000347577722926\n",
      "380 0.000331216589059\n",
      "381 0.000315627645765\n",
      "382 0.000300773929195\n",
      "383 0.000286625737914\n",
      "384 0.000273141283189\n",
      "385 0.000260291511655\n",
      "386 0.000248047299805\n",
      "387 0.000236383116532\n",
      "388 0.000225268902094\n",
      "389 0.000214676649149\n",
      "390 0.000204583481184\n",
      "391 0.000194966088537\n",
      "392 0.00018580455494\n",
      "393 0.000177071067539\n",
      "394 0.000168748937707\n",
      "395 0.000160819067543\n",
      "396 0.000153265182986\n",
      "397 0.000146065078862\n",
      "398 0.00013920313917\n",
      "399 0.000132664392071\n",
      "400 0.000126434847803\n",
      "401 0.000120498188935\n",
      "402 0.000114839727504\n",
      "403 0.000109447627027\n",
      "404 0.000104309487528\n",
      "405 9.94150099755e-05\n",
      "406 9.47485419594e-05\n",
      "407 9.03015420007e-05\n",
      "408 8.60635588663e-05\n",
      "409 8.20264656902e-05\n",
      "410 7.81778162397e-05\n",
      "411 7.45099687642e-05\n",
      "412 7.10144990349e-05\n",
      "413 6.76841420027e-05\n",
      "414 6.45100682975e-05\n",
      "415 6.14846161544e-05\n",
      "416 5.86012967699e-05\n",
      "417 5.5853700018e-05\n",
      "418 5.32358746462e-05\n",
      "419 5.07401085597e-05\n",
      "420 4.83617849629e-05\n",
      "421 4.60949160708e-05\n",
      "422 4.39353257598e-05\n",
      "423 4.18764109011e-05\n",
      "424 3.99140343438e-05\n",
      "425 3.80437514649e-05\n",
      "426 3.62617848018e-05\n",
      "427 3.45632505447e-05\n",
      "428 3.29441514856e-05\n",
      "429 3.14010090235e-05\n",
      "430 2.99304666883e-05\n",
      "431 2.85291820066e-05\n",
      "432 2.7193211929e-05\n",
      "433 2.5919886189e-05\n",
      "434 2.47063416796e-05\n",
      "435 2.35502147398e-05\n",
      "436 2.24478185382e-05\n",
      "437 2.13970394988e-05\n",
      "438 2.03955329753e-05\n",
      "439 1.94412294261e-05\n",
      "440 1.85316268039e-05\n",
      "441 1.76644508703e-05\n",
      "442 1.68379133844e-05\n",
      "443 1.60502034886e-05\n",
      "444 1.52995776008e-05\n",
      "445 1.45838692346e-05\n",
      "446 1.3901695416e-05\n",
      "447 1.3251481819e-05\n",
      "448 1.26319698061e-05\n",
      "449 1.204134033e-05\n",
      "450 1.1478266419e-05\n",
      "451 1.09415538611e-05\n",
      "452 1.04301076248e-05\n",
      "453 9.94259669694e-06\n",
      "454 9.47779654552e-06\n",
      "455 9.03475372171e-06\n",
      "456 8.6124927551e-06\n",
      "457 8.21013018601e-06\n",
      "458 7.82642801879e-06\n",
      "459 7.4606835878e-06\n",
      "460 7.11206486254e-06\n",
      "461 6.77988714027e-06\n",
      "462 6.46316459881e-06\n",
      "463 6.16124323086e-06\n",
      "464 5.87342937274e-06\n",
      "465 5.5991324409e-06\n",
      "466 5.33767438998e-06\n",
      "467 5.08837801071e-06\n",
      "468 4.85073820187e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469 4.62422219337e-06\n",
      "470 4.40839134748e-06\n",
      "471 4.20255091792e-06\n",
      "472 4.00633392738e-06\n",
      "473 3.81929323745e-06\n",
      "474 3.64105329482e-06\n",
      "475 3.47111573289e-06\n",
      "476 3.30911142329e-06\n",
      "477 3.15466255391e-06\n",
      "478 3.00744998574e-06\n",
      "479 2.86714735674e-06\n",
      "480 2.73335082552e-06\n",
      "481 2.60580667181e-06\n",
      "482 2.48422168128e-06\n",
      "483 2.36836138249e-06\n",
      "484 2.25787942979e-06\n",
      "485 2.1525465611e-06\n",
      "486 2.05213355386e-06\n",
      "487 1.95643393204e-06\n",
      "488 1.86520865813e-06\n",
      "489 1.77822692706e-06\n",
      "490 1.69529513918e-06\n",
      "491 1.61623990065e-06\n",
      "492 1.54090927346e-06\n",
      "493 1.46905809486e-06\n",
      "494 1.40056181102e-06\n",
      "495 1.33526432771e-06\n",
      "496 1.27303169058e-06\n",
      "497 1.21369791425e-06\n",
      "498 1.15712195879e-06\n",
      "499 1.10318545902e-06\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random input and output data\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h, 0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "\n",
    "    # Update weights\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.41335803 -0.27630649  0.359168    0.517661   -0.27703814 -0.15503262\n",
      "  -0.16544712 -2.2522237   1.50593503  0.02633928 -1.23188831  1.38167851\n",
      "  -0.22274565  2.21418405 -1.23104388 -0.73900898  0.83691879  0.81634632\n",
      "   0.69594281 -0.50236581  0.37172823  0.11494177  0.51234328  1.53879324\n",
      "  -1.71031223  0.64025297  1.9952436  -0.48186017 -2.21458357  0.23706741\n",
      "  -1.40077143 -1.21729859  0.5434545  -0.32193487  0.16135547 -0.22497608\n",
      "  -0.16058918 -0.60054574 -1.3470139   0.62734653  0.38725609  0.67589288\n",
      "   0.78290367 -0.56557718  1.23151855  0.16686588 -0.07669662  0.79427034\n",
      "   0.94045994  0.17051707  0.61686477  0.05541886 -0.24008393 -0.5657691\n",
      "   1.23076891  1.30273502  0.24660796  2.46996989 -0.69884694  0.75023105\n",
      "  -0.78310117  1.76952862  1.12919722 -0.26525799  0.13826414 -0.17183826\n",
      "   1.12460339  0.4125474  -1.94423085 -0.76125102 -0.27526855 -0.18652342\n",
      "   0.70066615 -0.47706781 -2.67177368 -0.5605498  -0.31757947  1.76850452\n",
      "  -1.64895592 -1.81075309 -1.16854908  0.03640064  0.31610979  2.25595496\n",
      "   0.24230687 -0.63014208  0.47993154 -0.67490779  0.2448583   1.4630333\n",
      "   0.45583212 -2.20384611  2.27811563  0.19732662 -0.89963538  1.17271783\n",
      "   0.20306935  0.06646339  1.05106585  0.23154338]\n",
      " [ 2.28158097  0.59064853  1.03755555  0.04542089  0.04195889 -0.80064605\n",
      "   2.64641369 -0.63053352  0.10732088 -1.03386741 -0.07147923  0.17845379\n",
      "  -0.62808716  1.01411289 -0.88413173  1.30149299 -0.1485473  -1.78489963\n",
      "  -0.74975181  0.17465683 -0.95255254  0.26335661  0.11265536 -0.40693237\n",
      "  -0.22475073 -1.10683698  0.70697472 -0.35050385  0.79055042 -0.72024186\n",
      "   1.14083329  0.38192484  2.03655773  0.65511769  0.36893805 -0.58858656\n",
      "  -0.76758182 -0.26587111  0.45399785 -0.31316467  0.40618366  1.20087287\n",
      "  -0.39580615  1.40629758 -1.61576102  0.32721651 -0.58912177  0.20186356\n",
      "   1.76550591 -0.41748824  0.46312438 -2.31452328  0.24450789 -0.27586064\n",
      "  -0.15007692  2.38029042 -0.9852516  -1.69508532  1.47303064  1.05960148\n",
      "  -0.13117881  0.09491436 -0.31305582  0.50970357 -0.27813239 -3.08572384\n",
      "   1.54425817  1.28814013 -1.04891332  1.43680776  0.00713298 -0.37199631\n",
      "   1.17169973  1.00615009 -0.7119809  -0.31500695 -0.02447024 -0.82462385\n",
      "  -0.6384025   1.54553209 -0.08898798  0.55252132  1.11522491  0.2567945\n",
      "  -1.08995841 -1.59545726  0.1329604   1.64188104  1.50189017 -0.05483619\n",
      "  -1.14911967 -0.26896189  1.50745472 -0.51403211 -0.34108739  1.2398788\n",
      "   0.28438963 -0.18707438 -0.32479185  0.29832932]]\n"
     ]
    }
   ],
   "source": [
    "print(w1[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch:Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 34963191.87537962\n",
      "1 31758398.310842745\n",
      "2 30779797.840503156\n",
      "3 27524276.210404396\n",
      "4 21132461.75903082\n",
      "5 13757626.22449712\n",
      "6 8047890.635958634\n",
      "7 4587742.711796384\n",
      "8 2767896.5901559275\n",
      "9 1835157.3529197685\n",
      "10 1336829.96795053\n",
      "11 1044971.3049204126\n",
      "12 855142.1286475183\n",
      "13 719432.0001630839\n",
      "14 615891.1750297444\n",
      "15 533328.5034282898\n",
      "16 465526.70592429675\n",
      "17 408884.13044927054\n",
      "18 360988.87659919204\n",
      "19 320107.82363601355\n",
      "20 284959.589747082\n",
      "21 254569.67567400137\n",
      "22 228150.43324431055\n",
      "23 205096.81125649545\n",
      "24 184887.08552131848\n",
      "25 167082.24959471665\n",
      "26 151346.54796543368\n",
      "27 137418.86937996204\n",
      "28 125047.97431748125\n",
      "29 114010.68094272952\n",
      "30 104140.72071048594\n",
      "31 95288.66964764954\n",
      "32 87349.27323596939\n",
      "33 80195.20120106603\n",
      "34 73735.20615720275\n",
      "35 67888.88383796069\n",
      "36 62584.314934329945\n",
      "37 57766.37647295765\n",
      "38 53385.29680317201\n",
      "39 49392.22550837782\n",
      "40 45749.07724639389\n",
      "41 42418.994681715936\n",
      "42 39370.11341914414\n",
      "43 36576.6053214102\n",
      "44 34013.14726743383\n",
      "45 31658.35322702598\n",
      "46 29491.680265169616\n",
      "47 27497.54036832041\n",
      "48 25659.953807391757\n",
      "49 23965.368073336213\n",
      "50 22399.820979058095\n",
      "51 20951.85359058552\n",
      "52 19611.877697032356\n",
      "53 18369.928686215542\n",
      "54 17218.348241322194\n",
      "55 16149.527786079187\n",
      "56 15156.609824486943\n",
      "57 14234.303753200209\n",
      "58 13376.114009782084\n",
      "59 12577.502739961448\n",
      "60 11833.372924594336\n",
      "61 11139.44949473314\n",
      "62 10491.727142849035\n",
      "63 9886.94004620364\n",
      "64 9322.605225581116\n",
      "65 8794.858980969937\n",
      "66 8300.791749162745\n",
      "67 7838.112532194005\n",
      "68 7404.594327828077\n",
      "69 6998.4192080671055\n",
      "70 6617.043243935024\n",
      "71 6259.140743593908\n",
      "72 5922.937687934045\n",
      "73 5607.078868391888\n",
      "74 5310.430608938374\n",
      "75 5031.588779702703\n",
      "76 4769.1707527952185\n",
      "77 4522.394459959174\n",
      "78 4289.828168149825\n",
      "79 4070.737467297098\n",
      "80 3864.0743876554016\n",
      "81 3669.0739261752533\n",
      "82 3485.0378292776713\n",
      "83 3311.1854819189944\n",
      "84 3147.5014278425024\n",
      "85 2992.8389434295686\n",
      "86 2846.6143053804362\n",
      "87 2708.294438997248\n",
      "88 2577.3971687664143\n",
      "89 2453.5229146065903\n",
      "90 2336.259928509438\n",
      "91 2225.115820540591\n",
      "92 2119.789652977618\n",
      "93 2019.9261335036233\n",
      "94 1925.2207611917636\n",
      "95 1835.3748310285782\n",
      "96 1750.1504991888592\n",
      "97 1669.2651823347383\n",
      "98 1592.4264614528051\n",
      "99 1519.4339586212093\n",
      "100 1450.1217515122419\n",
      "101 1384.2103982318868\n",
      "102 1321.5646030393143\n",
      "103 1262.0074341525833\n",
      "104 1205.3623584687289\n",
      "105 1151.4429507409586\n",
      "106 1100.161178337019\n",
      "107 1051.3265430416195\n",
      "108 1004.845872814225\n",
      "109 960.5778396463297\n",
      "110 918.4392761639361\n",
      "111 878.2632129959992\n",
      "112 839.9593524094462\n",
      "113 803.4652824995131\n",
      "114 768.6660207624878\n",
      "115 735.4880437242733\n",
      "116 703.8333411522815\n",
      "117 673.6603767352642\n",
      "118 644.856057573612\n",
      "119 617.3799660878615\n",
      "120 591.1471844978399\n",
      "121 566.1153375062736\n",
      "122 542.1953702582117\n",
      "123 519.3567550360555\n",
      "124 497.5362347631459\n",
      "125 476.6992342124076\n",
      "126 456.7797862107365\n",
      "127 437.75105099272\n",
      "128 419.5561684211499\n",
      "129 402.1883734437167\n",
      "130 385.5799244801308\n",
      "131 369.7069406180408\n",
      "132 354.5183649371349\n",
      "133 339.98873407640446\n",
      "134 326.0865561966734\n",
      "135 312.7867989373549\n",
      "136 300.05835511086593\n",
      "137 287.87788509173936\n",
      "138 276.2182331191058\n",
      "139 265.0593940262004\n",
      "140 254.37220658821354\n",
      "141 244.13692121159636\n",
      "142 234.34133084760197\n",
      "143 224.9595511429569\n",
      "144 215.96608751431643\n",
      "145 207.35334103986736\n",
      "146 199.09779266234443\n",
      "147 191.19214019750865\n",
      "148 183.62061860739976\n",
      "149 176.36587365274397\n",
      "150 169.40862875706296\n",
      "151 162.74266726389703\n",
      "152 156.34958000588665\n",
      "153 150.22362410098037\n",
      "154 144.34822524849505\n",
      "155 138.7127427748788\n",
      "156 133.30450328340464\n",
      "157 128.11936435760845\n",
      "158 123.14151944171272\n",
      "159 118.36670268382035\n",
      "160 113.78434568270997\n",
      "161 109.38902340405849\n",
      "162 105.1682778642062\n",
      "163 101.11870233949284\n",
      "164 97.2330060258584\n",
      "165 93.50152762353008\n",
      "166 89.92224935009813\n",
      "167 86.48279360272457\n",
      "168 83.17970159764256\n",
      "169 80.00864623435723\n",
      "170 76.96110821618072\n",
      "171 74.03619600109481\n",
      "172 71.2272702340128\n",
      "173 68.52849025659137\n",
      "174 65.93559018241298\n",
      "175 63.44379932848324\n",
      "176 61.05015499250902\n",
      "177 58.752313962949415\n",
      "178 56.54425902754089\n",
      "179 54.42132229053301\n",
      "180 52.38178620141075\n",
      "181 50.42036641811332\n",
      "182 48.53665021633982\n",
      "183 46.724900527043374\n",
      "184 44.98319323603131\n",
      "185 43.309181877236725\n",
      "186 41.698920127567035\n",
      "187 40.15051229306194\n",
      "188 38.662528737725225\n",
      "189 37.23063666271868\n",
      "190 35.85398104824357\n",
      "191 34.53065027424732\n",
      "192 33.257223968311415\n",
      "193 32.03252769335957\n",
      "194 30.85388352095994\n",
      "195 29.720389909888468\n",
      "196 28.62947295000663\n",
      "197 27.579826442781922\n",
      "198 26.56975905873788\n",
      "199 25.59824959044269\n",
      "200 24.66314691040853\n",
      "201 23.763298553970927\n",
      "202 22.896912923977027\n",
      "203 22.06335788031498\n",
      "204 21.26164146183409\n",
      "205 20.4893476131867\n",
      "206 19.746591367844378\n",
      "207 19.03070106585546\n",
      "208 18.34157201609789\n",
      "209 17.678418100605214\n",
      "210 17.039561576324108\n",
      "211 16.424425667065524\n",
      "212 15.832175625568212\n",
      "213 15.262035980197027\n",
      "214 14.712858335064496\n",
      "215 14.184677524427173\n",
      "216 13.674438261482884\n",
      "217 13.18421879632775\n",
      "218 12.711567624999105\n",
      "219 12.257376374337094\n",
      "220 11.819008698976752\n",
      "221 11.396940462111456\n",
      "222 10.989664590639197\n",
      "223 10.597676828940624\n",
      "224 10.220191559644345\n",
      "225 9.856257481912714\n",
      "226 9.505711717926566\n",
      "227 9.16778786483744\n",
      "228 8.842548685647234\n",
      "229 8.529021479693188\n",
      "230 8.226631606920012\n",
      "231 7.935299775719489\n",
      "232 7.654458213544945\n",
      "233 7.3840504422289435\n",
      "234 7.123462447192281\n",
      "235 6.871803857301472\n",
      "236 6.629640712687731\n",
      "237 6.395880700112659\n",
      "238 6.170929553147037\n",
      "239 5.954059981022141\n",
      "240 5.744564544102502\n",
      "241 5.542732194045541\n",
      "242 5.3482273242493505\n",
      "243 5.160923436230959\n",
      "244 4.979957754286421\n",
      "245 4.805861016959643\n",
      "246 4.637552519781838\n",
      "247 4.4755330589837286\n",
      "248 4.31938892815927\n",
      "249 4.168594943582633\n",
      "250 4.02333617802455\n",
      "251 3.8832780704348835\n",
      "252 3.747998658618954\n",
      "253 3.6173094189930026\n",
      "254 3.4918546599479257\n",
      "255 3.370357518241512\n",
      "256 3.253486778860573\n",
      "257 3.1405064395751694\n",
      "258 3.0314555411715\n",
      "259 2.9262760130325134\n",
      "260 2.825186943338643\n",
      "261 2.72731567874046\n",
      "262 2.632891632361442\n",
      "263 2.541962024019085\n",
      "264 2.4544534000460843\n",
      "265 2.3697599736250377\n",
      "266 2.2879227957192336\n",
      "267 2.2090998067188554\n",
      "268 2.1329304171796055\n",
      "269 2.0596476442477227\n",
      "270 1.9887453829392037\n",
      "271 1.9202856342234513\n",
      "272 1.8542985654368538\n",
      "273 1.7905512737179565\n",
      "274 1.729158829105434\n",
      "275 1.6698054058430394\n",
      "276 1.612655960288798\n",
      "277 1.557434267118147\n",
      "278 1.503919716928202\n",
      "279 1.4524421096466043\n",
      "280 1.4028606513886714\n",
      "281 1.3549209602494923\n",
      "282 1.3086529373880378\n",
      "283 1.2639198604828792\n",
      "284 1.2208697067531595\n",
      "285 1.179120690711084\n",
      "286 1.1390000146447292\n",
      "287 1.1000024073418615\n",
      "288 1.0625680231758565\n",
      "289 1.026426497463703\n",
      "290 0.9914414252298087\n",
      "291 0.9578326810721167\n",
      "292 0.9252347512680796\n",
      "293 0.8938340594971239\n",
      "294 0.8634505297877377\n",
      "295 0.8341400580070442\n",
      "296 0.8058940535330168\n",
      "297 0.7786311464497757\n",
      "298 0.7522288394895684\n",
      "299 0.7266936422191792\n",
      "300 0.7020519143500021\n",
      "301 0.6783356353475654\n",
      "302 0.6553979786094466\n",
      "303 0.6332273156625376\n",
      "304 0.6118745596762842\n",
      "305 0.5911900698454566\n",
      "306 0.5712086997882189\n",
      "307 0.5519067500386869\n",
      "308 0.5333391909667178\n",
      "309 0.5153415367019143\n",
      "310 0.49796567740249476\n",
      "311 0.4812087057312242\n",
      "312 0.4649473946941116\n",
      "313 0.44934524659014574\n",
      "314 0.4342776885984252\n",
      "315 0.41965204657150856\n",
      "316 0.40552471015595604\n",
      "317 0.3918185288592344\n",
      "318 0.3787228022787881\n",
      "319 0.36603916144335535\n",
      "320 0.35369683382296735\n",
      "321 0.3418147940098537\n",
      "322 0.33034701492730356\n",
      "323 0.3192735087400296\n",
      "324 0.30857387322231933\n",
      "325 0.2982244269511778\n",
      "326 0.2882745803353952\n",
      "327 0.27863720179660767\n",
      "328 0.2693442917975606\n",
      "329 0.26032932226638117\n",
      "330 0.2516208320240043\n",
      "331 0.2431925435923521\n",
      "332 0.23506544729349876\n",
      "333 0.22724058257813873\n",
      "334 0.21964067371771456\n",
      "335 0.2122912818660101\n",
      "336 0.20522095420305764\n",
      "337 0.19838607820663623\n",
      "338 0.1917679475107601\n",
      "339 0.1853235286809154\n",
      "340 0.17916716663166365\n",
      "341 0.173208054279141\n",
      "342 0.16744206707328235\n",
      "343 0.16184275047740315\n",
      "344 0.1564757934996257\n",
      "345 0.15125729942285382\n",
      "346 0.14624896560357414\n",
      "347 0.1413994761087045\n",
      "348 0.13671141501044048\n",
      "349 0.13216731709568408\n",
      "350 0.127776829559471\n",
      "351 0.12355448897666399\n",
      "352 0.11944666396004955\n",
      "353 0.11551381212593448\n",
      "354 0.11167902838345434\n",
      "355 0.10795391766567608\n",
      "356 0.1043785231083536\n",
      "357 0.10092805827516393\n",
      "358 0.09757005178110312\n",
      "359 0.09436896446105614\n",
      "360 0.09122879560055885\n",
      "361 0.0882207306201428\n",
      "362 0.0853166479109948\n",
      "363 0.08248020432811054\n",
      "364 0.07976052163254477\n",
      "365 0.07710761196467808\n",
      "366 0.07459119703841144\n",
      "367 0.07213571315107115\n",
      "368 0.06975776692271052\n",
      "369 0.06747033373202194\n",
      "370 0.06523789665849855\n",
      "371 0.06308540591661949\n",
      "372 0.0610041260846812\n",
      "373 0.05897510652616933\n",
      "374 0.05704092311394238\n",
      "375 0.05517789687113783\n",
      "376 0.053348195645808616\n",
      "377 0.05161147269020194\n",
      "378 0.04990931584232694\n",
      "379 0.048279797802740276\n",
      "380 0.046672175996125276\n",
      "381 0.04513171632078794\n",
      "382 0.043655143888964076\n",
      "383 0.0422280661834904\n",
      "384 0.04084642443850939\n",
      "385 0.03951665960013162\n",
      "386 0.038220036089766984\n",
      "387 0.036958596276213895\n",
      "388 0.03574415897869876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389 0.03458460739011737\n",
      "390 0.03346482979144161\n",
      "391 0.03236769104491183\n",
      "392 0.03130550151582623\n",
      "393 0.03028465144783926\n",
      "394 0.02930539736679766\n",
      "395 0.028341548944012973\n",
      "396 0.027416086714324273\n",
      "397 0.026531072794243826\n",
      "398 0.025665981042339747\n",
      "399 0.024830335077790866\n",
      "400 0.024034285178015646\n",
      "401 0.023249458555705593\n",
      "402 0.022491855839511188\n",
      "403 0.021758370235466784\n",
      "404 0.02104902409897358\n",
      "405 0.02036806999276264\n",
      "406 0.019719938981979546\n",
      "407 0.01908075929528502\n",
      "408 0.01847326928990789\n",
      "409 0.01788297509570115\n",
      "410 0.017304520195069506\n",
      "411 0.01673973565686722\n",
      "412 0.016199401334447545\n",
      "413 0.015690908665129177\n",
      "414 0.015182894566587724\n",
      "415 0.014701349809381037\n",
      "416 0.014238627475978038\n",
      "417 0.013780780831464334\n",
      "418 0.013341487303765442\n",
      "419 0.012918226656578047\n",
      "420 0.012509895994127052\n",
      "421 0.01211336257530915\n",
      "422 0.011729548956645963\n",
      "423 0.011352941997790855\n",
      "424 0.010990418243014666\n",
      "425 0.01064447669055979\n",
      "426 0.01030714729439991\n",
      "427 0.009984958506515887\n",
      "428 0.009673913733188544\n",
      "429 0.009372769297568972\n",
      "430 0.009083092946670826\n",
      "431 0.008795483396504378\n",
      "432 0.008517762798552098\n",
      "433 0.008252291435924666\n",
      "434 0.007995735675639451\n",
      "435 0.007753621854071871\n",
      "436 0.007510502738944672\n",
      "437 0.00727587765274779\n",
      "438 0.007048664460697018\n",
      "439 0.0068325910370813925\n",
      "440 0.006623707310843219\n",
      "441 0.006416341879810383\n",
      "442 0.006217279571742784\n",
      "443 0.006025912515945753\n",
      "444 0.005843146404066191\n",
      "445 0.005661739172507285\n",
      "446 0.005496029332252683\n",
      "447 0.005328151120197799\n",
      "448 0.005167605931819086\n",
      "449 0.005010108768482291\n",
      "450 0.004860370636229572\n",
      "451 0.004714197848418977\n",
      "452 0.004574581830289803\n",
      "453 0.004438655056998919\n",
      "454 0.004305178971015788\n",
      "455 0.004170614369515158\n",
      "456 0.004052050347510605\n",
      "457 0.003931624323145144\n",
      "458 0.003818049769697851\n",
      "459 0.0037054074721692976\n",
      "460 0.0035990637892163724\n",
      "461 0.003492617611137172\n",
      "462 0.0033927952429568253\n",
      "463 0.0032952340428672594\n",
      "464 0.0032003018425204033\n",
      "465 0.0031095401947585644\n",
      "466 0.00301769143243813\n",
      "467 0.00293237013622194\n",
      "468 0.0028506324557609486\n",
      "469 0.0027688349371456367\n",
      "470 0.002692350894906159\n",
      "471 0.0026155569623346198\n",
      "472 0.002541341793574795\n",
      "473 0.002470238991240936\n",
      "474 0.0024024456181340748\n",
      "475 0.0023354355479043333\n",
      "476 0.0022714479873218174\n",
      "477 0.002208253700221152\n",
      "478 0.0021498402789575377\n",
      "479 0.0020905285941557605\n",
      "480 0.0020336345852164928\n",
      "481 0.0019779853727938113\n",
      "482 0.0019238165493956627\n",
      "483 0.001874659528214695\n",
      "484 0.001824293232781049\n",
      "485 0.0017749652443843633\n",
      "486 0.0017285525618023767\n",
      "487 0.001683767886073828\n",
      "488 0.0016416001108259248\n",
      "489 0.0015981001643282644\n",
      "490 0.0015552678907132522\n",
      "491 0.0015153716655751381\n",
      "492 0.0014768600794649034\n",
      "493 0.001438255100006336\n",
      "494 0.0014007185345246698\n",
      "495 0.0013658203674448144\n",
      "496 0.0013304506502024305\n",
      "497 0.0012980654155330673\n",
      "498 0.001267449563437606\n",
      "499 0.0012362657859040227\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.randn(N, D_in).type(dtype)\n",
    "y = torch.randn(N, D_out).type(dtype)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = torch.randn(D_in, H).type(dtype)\n",
    "w2 = torch.randn(H, D_out).type(dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.mm(w1)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.41335803 -0.27630649  0.359168    0.517661   -0.27703814 -0.15503262\n",
      "  -0.16544712 -2.2522237   1.50593503  0.02633928 -1.23188831  1.38167851\n",
      "  -0.22274565  2.21418405 -1.23104388 -0.73900898  0.83691879  0.81634632\n",
      "   0.69594281 -0.50236581  0.37172823  0.11494177  0.51234328  1.53879324\n",
      "  -1.71031223  0.64025297  1.9952436  -0.48186017 -2.21458357  0.23706741\n",
      "  -1.40077143 -1.21729859  0.5434545  -0.32193487  0.16135547 -0.22497608\n",
      "  -0.16058918 -0.60054574 -1.3470139   0.62734653  0.38725609  0.67589288\n",
      "   0.78290367 -0.56557718  1.23151855  0.16686588 -0.07669662  0.79427034\n",
      "   0.94045994  0.17051707  0.61686477  0.05541886 -0.24008393 -0.5657691\n",
      "   1.23076891  1.30273502  0.24660796  2.46996989 -0.69884694  0.75023105\n",
      "  -0.78310117  1.76952862  1.12919722 -0.26525799  0.13826414 -0.17183826\n",
      "   1.12460339  0.4125474  -1.94423085 -0.76125102 -0.27526855 -0.18652342\n",
      "   0.70066615 -0.47706781 -2.67177368 -0.5605498  -0.31757947  1.76850452\n",
      "  -1.64895592 -1.81075309 -1.16854908  0.03640064  0.31610979  2.25595496\n",
      "   0.24230687 -0.63014208  0.47993154 -0.67490779  0.2448583   1.4630333\n",
      "   0.45583212 -2.20384611  2.27811563  0.19732662 -0.89963538  1.17271783\n",
      "   0.20306935  0.06646339  1.05106585  0.23154338]\n",
      " [ 2.28158097  0.59064853  1.03755555  0.04542089  0.04195889 -0.80064605\n",
      "   2.64641369 -0.63053352  0.10732088 -1.03386741 -0.07147923  0.17845379\n",
      "  -0.62808716  1.01411289 -0.88413173  1.30149299 -0.1485473  -1.78489963\n",
      "  -0.74975181  0.17465683 -0.95255254  0.26335661  0.11265536 -0.40693237\n",
      "  -0.22475073 -1.10683698  0.70697472 -0.35050385  0.79055042 -0.72024186\n",
      "   1.14083329  0.38192484  2.03655773  0.65511769  0.36893805 -0.58858656\n",
      "  -0.76758182 -0.26587111  0.45399785 -0.31316467  0.40618366  1.20087287\n",
      "  -0.39580615  1.40629758 -1.61576102  0.32721651 -0.58912177  0.20186356\n",
      "   1.76550591 -0.41748824  0.46312438 -2.31452328  0.24450789 -0.27586064\n",
      "  -0.15007692  2.38029042 -0.9852516  -1.69508532  1.47303064  1.05960148\n",
      "  -0.13117881  0.09491436 -0.31305582  0.50970357 -0.27813239 -3.08572384\n",
      "   1.54425817  1.28814013 -1.04891332  1.43680776  0.00713298 -0.37199631\n",
      "   1.17169973  1.00615009 -0.7119809  -0.31500695 -0.02447024 -0.82462385\n",
      "  -0.6384025   1.54553209 -0.08898798  0.55252132  1.11522491  0.2567945\n",
      "  -1.08995841 -1.59545726  0.1329604   1.64188104  1.50189017 -0.05483619\n",
      "  -1.14911967 -0.26896189  1.50745472 -0.51403211 -0.34108739  1.2398788\n",
      "   0.28438963 -0.18707438 -0.32479185  0.29832932]]\n"
     ]
    }
   ],
   "source": [
    "print(w1[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch:Variables and autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 32038038.0\n1 24540900.0\n2 21295138.0\n3 18534806.0\n4 15360310.0\n5 11703360.0\n6 8338559.0\n7 5633266.0\n8 3750787.5\n9 2515682.5\n10 1741623.125\n11 1254278.25\n12 943072.0625\n13 736827.9375\n14 594431.25\n15 491512.75\n16 413996.03125\n17 353387.21875\n18 304663.21875\n19 264679.65625\n20 231333.9375\n21 203136.453125\n22 179086.71875\n23 158409.953125\n24 140544.109375\n25 125014.0546875\n26 111468.0390625\n27 99609.6640625\n28 89198.0390625\n29 80032.6640625\n30 71944.2578125\n31 64789.22265625\n32 58441.98046875\n33 52801.5234375\n34 47775.33984375\n35 43288.828125\n36 39276.20703125\n37 35683.15625\n38 32457.630859375\n39 29558.095703125\n40 26949.033203125\n41 24597.3515625\n42 22474.9609375\n43 20557.271484375\n44 18823.845703125\n45 17252.75390625\n46 15825.51953125\n47 14529.150390625\n48 13350.8046875\n49 12278.087890625\n50 11299.9638671875\n51 10408.2861328125\n52 9594.9697265625\n53 8853.4736328125\n54 8175.34326171875\n55"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7554.32763671875\n56 6985.349609375\n57 6463.353515625\n58 5983.9765625\n59 5543.662109375\n60 5138.7294921875\n61 4766.03564453125\n62 4422.80419921875\n63 4106.390625\n64 3814.58056640625\n65 3545.354736328125\n66 3296.777099609375\n67 3066.939208984375\n68 2854.4267578125\n69 2657.8857421875\n70 2475.92529296875\n71 2307.3818359375\n72 2151.12890625\n73 2006.3272705078125\n74 1871.9207763671875\n75 1747.1121826171875\n76 1631.2264404296875\n77 1523.57373046875\n78 1423.475830078125\n79 1330.3865966796875\n80 1243.8253173828125\n81 1163.218505859375\n82 1088.1932373046875\n83 1018.3486328125\n84 953.2637939453125\n85 892.5757446289062\n86 835.9678955078125\n87 783.1720581054688\n88 733.876953125\n89 687.8726806640625\n90 645.03076171875\n91 604.9949340820312\n92 567.5805053710938\n93 532.5977172851562\n94 499.8784484863281\n95 469.25909423828125\n96 440.6116943359375\n97 413.8350830078125\n98 388.7604675292969\n99 365.27508544921875\n100 343.2707214355469\n101 322.6514587402344\n102 303.3289489746094\n103 285.2069091796875\n104 268.20587158203125\n105 252.2588653564453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 237.29287719726562\n107 223.25123596191406\n108 210.07432556152344\n109 197.70889282226562\n110 186.09197998046875\n111 175.18035888671875\n112 164.93077087402344\n113 155.30039978027344\n114 146.25279235839844\n115 137.75027465820312\n116 129.75608825683594\n117 122.24222564697266\n118 115.173095703125\n119 108.5241928100586\n120 102.27283477783203\n121 96.3892593383789\n122 90.85509490966797\n123 85.64384460449219\n124 80.74143981933594\n125 76.12638854980469\n126 71.78147888183594\n127 67.6900863647461\n128 63.83808135986328\n129 60.209800720214844\n130 56.793087005615234\n131 53.573448181152344\n132 50.54216766357422\n133 47.684078216552734\n134 44.99227523803711\n135 42.456207275390625\n136 40.06573486328125\n137 37.81229782104492\n138 35.68799591064453\n139 33.6863899230957\n140 31.79836082458496\n141 30.01850128173828\n142 28.339839935302734\n143 26.7564754486084\n144 25.26338005065918\n145 23.853572845458984\n146 22.525224685668945\n147 21.27145004272461\n148 20.08844566345215\n149 18.972333908081055\n150 17.919694900512695\n151 16.925474166870117\n152 15.98798656463623\n153 15.102386474609375\n154 14.266939163208008\n155 13.478048324584961\n156 12.733267784118652\n157 12.031044006347656\n158 11.367202758789062\n159 10.740485191345215\n160 10.149075508117676\n161 9.590641021728516\n162 9.063780784606934\n163 8.56570053100586\n164 8.094770431518555\n165"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7.650430202484131\n166 7.230819225311279\n167 6.834444999694824\n168 6.460161209106445\n169 6.106148719787598\n170 5.772151947021484\n171 5.456573009490967\n172 5.158533096313477\n173 4.876955509185791\n174 4.610554218292236\n175 4.358875274658203\n176 4.120862007141113\n177 3.896280527114868\n178 3.6842939853668213\n179 3.48344349861145\n180 3.2939517498016357\n181 3.114673614501953\n182 2.9453787803649902\n183 2.7852509021759033\n184 2.6338768005371094\n185 2.4908909797668457\n186 2.355743408203125\n187 2.2279438972473145\n188 2.1071979999542236\n189 1.9929428100585938\n190 1.8849307298660278\n191 1.7829198837280273\n192 1.6863386631011963\n193 1.5951772928237915\n194 1.508824348449707\n195 1.4274152517318726\n196 1.3501797914505005\n197 1.2772825956344604\n198 1.2081944942474365\n199 1.1429659128189087\n200 1.0813239812850952\n201 1.0230135917663574\n202 0.9678789973258972\n203 0.9155924320220947\n204 0.8663339614868164\n205 0.8195538520812988\n206 0.7754507660865784\n207 0.7338109016418457\n208 0.6943713426589966\n209 0.6569307446479797\n210 0.6215327978134155\n211 0.5881525874137878\n212 0.5565734505653381\n213 0.5266546607017517\n214 0.4983270466327667\n215 0.4716581106185913\n216 0.44632863998413086\n217 0.4224061369895935\n218 0.39970606565475464\n219 0.37819716334342957\n220 0.3580227494239807\n221 0.3387569785118103\n222 0.3206287920475006\n223 0.30345335602760315\n224 0.28712067008018494\n225 0.27180418372154236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 0.2572302520275116\n227 0.24343448877334595\n228 0.23043248057365417\n229 0.21811583638191223\n230 0.2064489722251892\n231 0.1954488605260849\n232 0.18495580554008484\n233 0.17507241666316986\n234 0.16574567556381226\n235 0.15686292946338654\n236 0.14848141372203827\n237 0.14053629338741302\n238 0.13304096460342407\n239 0.12593673169612885\n240 0.119200199842453\n241 0.11287379264831543\n242 0.10686289519071579\n243 0.1011849194765091\n244 0.09576968103647232\n245 0.090652696788311\n246 0.0858093723654747\n247 0.08124350756406784\n248 0.07693305611610413\n249 0.07284402847290039\n250 0.06897816061973572\n251 0.06530360877513885\n252 0.06183571368455887\n253 0.0585390143096447\n254 0.055435676127672195\n255 0.05246060714125633\n256 0.04968675598502159\n257 0.047056447714567184\n258 0.044550973922014236\n259 0.04220370948314667\n260 0.03995318338274956\n261 0.03783733397722244\n262 0.03583119064569473\n263 0.03395213559269905\n264 0.032117728143930435\n265 0.03040659800171852\n266 0.02880794368684292\n267 0.027283910661935806\n268 0.025839166715741158\n269 0.024485519155859947\n270 0.02318471483886242\n271 0.021955635398626328\n272 0.020804760977625847\n273 0.019713476300239563\n274 0.01866941712796688\n275 0.01767664961516857\n276 0.016762426123023033\n277 0.0158720500767231\n278 0.015051351860165596\n279 0.014253643341362476\n280 0.013520468026399612\n281 0.012811841443181038\n282 0.01215993333607912\n283 0.011519461870193481\n284 0.01092439889907837\n285 0.01035337708890438\n286 0.009815526194870472\n287 0.00930058117955923\n288 0.008829440921545029\n289 0.00837617740035057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290 0.007940239273011684\n291 0.0075368620455265045\n292 0.007146667223423719\n293 0.006783111486583948\n294 0.006437069736421108\n295 0.006101834122091532\n296 0.005794273689389229\n297 0.005505395121872425\n298 0.005230781622231007\n299 0.004961474798619747\n300 0.004715106450021267\n301 0.0044805267825722694\n302 0.004256303422152996\n303 0.004049175418913364\n304 0.0038523278199136257\n305 0.003655241569504142\n306 0.003479556879028678\n307 0.0033115174155682325\n308 0.0031518531031906605\n309 0.002998708514496684\n310 0.002856286708265543\n311 0.0027187569066882133\n312 0.002589945215731859\n313 0.0024682674556970596\n314 0.0023511573672294617\n315 0.002242390299215913\n316 0.0021366768050938845\n317 0.0020424064714461565\n318 0.0019448080565780401\n319 0.0018573899287730455\n320 0.0017748690443113446\n321 0.0016950778663158417\n322 0.0016184744890779257\n323 0.0015479883877560496\n324 0.0014815201284363866\n325 0.0014168255729600787\n326 0.0013529156567528844\n327 0.0012932221870869398\n328 0.0012376951053738594\n329 0.0011840314837172627\n330 0.0011340955970808864\n331 0.001089027151465416\n332 0.0010433391435071826\n333 0.0009996328735724092\n334 0.0009585846564732492\n335 0.0009214985184371471\n336 0.0008833555039018393\n337 0.0008459205855615437\n338 0.0008118163095787168\n339 0.0007816003635525703\n340 0.000748908962123096\n341 0.0007217024103738368\n342 0.0006941608735360205\n343 0.0006682761595584452\n344 0.0006440463475883007\n345 0.0006197125767357647\n346 0.0005986593896523118\n347 0.0005760654457844794\n348 0.0005549669731408358\n349 0.0005348839331418276\n350 0.0005171816446818411\n351 0.0004988839500583708\n352 0.00048119205166585743\n353 0.00046485793427564204\n354 0.0004480874340515584\n355 0.0004329531511757523\n356 0.000418186595197767\n357 0.000404239195631817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358 0.00039006239967420697\n359 0.0003782172279898077\n360 0.00036575787817128\n361 0.0003533755079843104\n362 0.00034303925349377096\n363 0.0003322878619655967\n364 0.00032157450914382935\n365 0.00031128269620239735\n366 0.00030259203049354255\n367 0.0002926176821347326\n368 0.0002835914201568812\n369 0.0002745365782175213\n370 0.0002665740030352026\n371 0.00025928555987775326\n372 0.000252192112384364\n373 0.00024411182675976306\n374 0.00023805766250006855\n375 0.0002309296396560967\n376 0.00022408735821954906\n377 0.00021807412849739194\n378 0.00021289415599312633\n379 0.0002071852795779705\n380 0.00020139261323492974\n381 0.00019639823585748672\n382 0.00019146146951243281\n383 0.00018632480350788683\n384 0.00018093417747877538\n385 0.00017703909543342888\n386 0.00017247504729311913\n387 0.0001679814886301756\n388 0.00016401389439124614\n389 0.0001592343469383195\n390 0.00015571397671010345\n391 0.00015183423238340765\n392 0.00014798234042245895\n393 0.0001441175554646179\n394 0.0001402085617883131\n395 0.00013724103337153792\n396 0.00013373352703638375\n397 0.00013082459918223321\n398 0.0001273268717341125\n399 0.00012466704356484115\n400 0.00012155672447988763\n401 0.00011894727504113689\n402 0.00011622748570516706\n403 0.00011357610492268577\n404 0.00011143065785290673\n405 0.00010843550262507051\n406 0.0001063936433638446\n407 0.00010444090730743483\n408 0.00010198838572250679\n409 9.945302008418366e-05\n410 9.800999396247789e-05\n411 9.551618859404698e-05\n412 9.381899872096255e-05\n413 9.200754720950499e-05\n414 9.009695349959657e-05\n415 8.88106515049003e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416 8.705337677383795e-05\n417 8.533653453923762e-05\n418 8.343967056134716e-05\n419 8.160547440638766e-05\n420 8.020843961276114e-05\n421 7.869468390708789e-05\n422 7.685824675718322e-05\n423 7.521727093262598e-05\n424 7.387076766462997e-05\n425 7.282539445441216e-05\n426 7.1668931923341e-05\n427 7.055050082271919e-05\n428 6.910503725521266e-05\n429 6.802688585594296e-05\n430 6.656846380792558e-05\n431 6.52564485790208e-05\n432 6.399297853931785e-05\n433 6.289764132816344e-05\n434 6.185967504279688e-05\n435 6.0859925724798813e-05\n436 5.991105717839673e-05\n437 5.905852231080644e-05\n438 5.818805220769718e-05\n439 5.713227074011229e-05\n440 5.6420474720653147e-05\n441 5.550435889745131e-05\n442 5.448335286928341e-05\n443 5.378965215641074e-05\n444 5.2675204642582685e-05\n445 5.207396316109225e-05\n446 5.1353665185160935e-05\n447 5.04595045640599e-05\n448 4.989410444977693e-05\n449 4.892618380836211e-05\n450 4.8142854211619124e-05\n451 4.7570829337928444e-05\n452 4.660353806684725e-05\n453 4.5955152017995715e-05\n454 4.546960553852841e-05\n455 4.465302481548861e-05\n456 4.41415177192539e-05\n457 4.38241331721656e-05\n458 4.297167106415145e-05\n459 4.245802483637817e-05\n460 4.1858838812913746e-05\n461 4.1336363210575655e-05\n462 4.066792826051824e-05\n463 4.0091828850563616e-05\n464 3.933963307645172e-05\n465 3.8769438106101006e-05\n466 3.829656998277642e-05\n467 3.7699370295740664e-05\n468 3.724404814420268e-05\n469 3.691365782287903e-05\n470 3.657805791590363e-05\n471 3.616807225625962e-05\n472 3.558194657671265e-05\n473 3.5185807064408436e-05\n474 3.471485251793638e-05\n475 3.426560579100624e-05\n476 3.397245018277317e-05\n477 3.3662672649370506e-05\n478 3.3019234251696616e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479 3.2473693863721564e-05\n480 3.206146357115358e-05\n481 3.176319660269655e-05\n482 3.134517464786768e-05\n483 3.079694215557538e-05\n484 3.041371746803634e-05\n485 3.0109005820122547e-05\n486 2.9860246286261827e-05\n487 2.9591254133265465e-05\n488 2.915511686296668e-05\n489 2.8798858693335205e-05\n490 2.844579103111755e-05\n491 2.8146541808382608e-05\n492 2.786076584015973e-05\n493 2.7627265808405355e-05\n494 2.7382502594264224e-05\n495 2.7096080884803087e-05\n496 2.681326077436097e-05\n497 2.6316205548937432e-05\n498 2.6231404262944125e-05\n499 2.6049718144349754e-05\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold input and outputs, and wrap them in Variables.\n",
    "# Setting requires_grad=False indicates that we do not need to compute gradients\n",
    "# with respect to these Variables during the backward pass.\n",
    "x = Variable(torch.randn(N, D_in).type(dtype), requires_grad=False)\n",
    "y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)\n",
    "\n",
    "# Create random Tensors for weights, and wrap them in Variables.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Variables during the backward pass.\n",
    "w1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=True)\n",
    "w2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y using operations on Variables; these\n",
    "    # are exactly the same operations we used to compute the forward pass using\n",
    "    # Tensors, but we do not need to keep references to intermediate values since\n",
    "    # we are not implementing the backward pass by hand.\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "\n",
    "    # Compute and print loss using operations on Variables.\n",
    "    # Now loss is a Variable of shape (1,) and loss.data is a Tensor of shape\n",
    "    # (1,); loss.data[0] is a scalar value holding the loss.\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.data[0])\n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Variables with requires_grad=True.\n",
    "    # After this call w1.grad and w2.grad will be Variables holding the gradient\n",
    "    # of the loss with respect to w1 and w2 respectively.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent; w1.data and w2.data are Tensors,\n",
    "    # w1.grad and w2.grad are Variables and w1.grad.data and w2.grad.data are\n",
    "    # Tensors.\n",
    "    w1.data -= learning_rate * w1.grad.data\n",
    "    w2.data -= learning_rate * w2.grad.data\n",
    "\n",
    "    # Manually zero the gradients after updating weights\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch: Defining new autograd functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 32152088.0\n1 29005144.0\n2 30154456.0\n3 30374218.0\n4 26417456.0\n5 18976170.0\n6 11358790.0\n7 6164444.0\n8 3344775.25\n9 1978773.625\n10 1315890.25\n11 971621.5\n12 770799.0625\n13 638308.375\n14 541839.5\n15 466734.0\n16 406154.96875\n17 355853.03125\n18 313355.09375\n19 277117.78125\n20 245977.859375\n21 219062.5625\n22 195688.109375\n23 175269.28125\n24 157366.625\n25 141603.84375\n26 127698.28125\n27 115396.1015625\n28 104481.9453125\n29 94758.5703125\n30 86072.4140625\n31 78307.359375\n32 71343.9609375\n33 65085.5546875\n34 59450.5390625\n35 54367.2578125\n36 49774.90234375\n37 45615.97265625\n38 41851.0625\n39 38434.4765625\n40 35328.203125\n41 32500.279296875\n42 29922.216796875\n43 27570.189453125\n44 25425.4921875\n45 23464.4140625\n46 21669.859375\n47 20026.17578125\n48 18518.775390625\n49 17135.091796875\n50 15864.697265625\n51 14696.806640625\n52 13622.24609375"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n53 12633.0751953125\n54 11721.76171875\n55 10881.794921875\n56 10107.1494140625\n57 9391.662109375\n58 8730.6708984375\n59 8119.619140625\n60 7554.2021484375\n61 7030.8720703125\n62 6546.330078125\n63 6097.49755859375\n64 5681.78857421875\n65 5296.240234375\n66 4938.56005859375\n67 4606.765625\n68 4298.681640625\n69 4012.458251953125\n70 3746.462158203125\n71 3499.161376953125\n72 3269.24609375\n73 3055.404296875\n74 2856.236328125\n75 2670.6787109375\n76 2497.84912109375\n77 2336.7705078125\n78 2186.620361328125\n79 2046.5399169921875\n80 1915.8646240234375\n81 1793.9537353515625\n82 1680.17822265625\n83 1574.005859375\n84 1474.818359375\n85 1382.142822265625\n86 1295.69384765625\n87 1214.9681396484375\n88 1139.5230712890625\n89 1069.0091552734375\n90 1002.9926147460938\n91 941.2102661132812\n92 883.4002685546875\n93 829.2850952148438\n94 778.6058959960938\n95 731.1625366210938\n96 686.7222900390625\n97 645.0859375\n98 606.0640258789062\n99 569.4865112304688\n100 535.1994018554688\n101 503.0568542480469\n102 472.9092102050781\n103 444.6382751464844"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n104 418.09771728515625\n105 393.20135498046875\n106 369.83856201171875\n107 347.9032287597656\n108 327.3045959472656\n109 307.9629211425781\n110 289.7973327636719\n111 272.7383728027344\n112 256.7237548828125\n113 241.673583984375\n114 227.520263671875\n115 214.22633361816406\n116 201.72750854492188\n117 189.97454833984375\n118 178.93080139160156\n119 168.54270935058594\n120 158.77117919921875\n121 149.58367919921875\n122 140.94178771972656\n123 132.8114013671875\n124 125.16455841064453\n125 117.96381378173828\n126 111.18547821044922\n127 104.80914306640625\n128 98.80650329589844\n129 93.15509796142578\n130 87.83956909179688\n131 82.85795593261719\n132 78.16388702392578\n133 73.74130249023438\n134 69.57772827148438\n135 65.65300750732422\n136 61.95315170288086\n137 58.46809768676758\n138 55.1831169128418\n139 52.08754348754883\n140 49.16859436035156\n141 46.416500091552734\n142 43.82054901123047\n143 41.373779296875\n144 39.066688537597656\n145 36.889793395996094\n146 34.837127685546875\n147 32.900352478027344\n148 31.073522567749023\n149 29.34952163696289\n150 27.723257064819336\n151 26.1888484954834\n152 24.739933013916016\n153 23.37347412109375\n154 22.083534240722656\n155 20.866273880004883\n156 19.716951370239258\n157 18.631559371948242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 17.607135772705078\n159 16.64018440246582\n160 15.726341247558594\n161 14.864336967468262\n162 14.049666404724121\n163 13.281764030456543\n164 12.55502986907959\n165 11.868792533874512\n166 11.220978736877441\n167 10.609169960021973\n168 10.03023910522461\n169 9.484163284301758\n170 8.967876434326172\n171 8.480229377746582\n172 8.0189208984375\n173 7.5835185050964355\n174 7.172152042388916\n175 6.7833709716796875\n176 6.415930271148682\n177 6.068650245666504\n178 5.739925861358643\n179 5.429782867431641\n180 5.136145114898682\n181 4.858702182769775\n182 4.596557140350342\n183 4.348907947540283\n184 4.114568710327148\n185 3.8931727409362793\n186 3.683460235595703\n187 3.4853737354278564\n188 3.2978415489196777\n189 3.1205763816833496\n190 2.9529738426208496\n191 2.794664144515991\n192 2.6447389125823975\n193 2.502906084060669\n194 2.368863821029663\n195 2.2421305179595947\n196 2.1218807697296143\n197 2.0085337162017822\n198 1.9013776779174805\n199 1.7995847463607788\n200 1.7034692764282227\n201 1.6126337051391602\n202 1.5265140533447266\n203 1.4449981451034546\n204 1.3680565357208252\n205 1.2950623035430908\n206 1.2261302471160889\n207 1.1608628034591675\n208 1.0991977453231812\n209 1.0407642126083374\n210 0.9854680895805359\n211 0.9330089688301086\n212 0.8834951519966125\n213 0.8367165923118591\n214 0.7922204732894897\n215 0.7501775622367859\n216 0.7104276418685913\n217 0.6727094054222107\n218 0.6370632648468018\n219"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.6034026741981506\n220 0.5715525150299072\n221 0.5411951541900635\n222 0.5125959515571594\n223 0.48547863960266113\n224 0.4598466455936432\n225 0.43556979298591614\n226 0.4125365912914276\n227 0.3907815217971802\n228 0.37022504210472107\n229 0.35069772601127625\n230 0.3321220576763153\n231 0.3146767020225525\n232 0.2980729341506958\n233 0.28235331177711487\n234 0.2675357758998871\n235 0.25341394543647766\n236 0.24009831249713898\n237 0.22749660909175873\n238 0.21552810072898865\n239 0.20417894423007965\n240 0.19349387288093567\n241 0.18328768014907837\n242 0.17367921769618988\n243 0.16455499827861786\n244 0.15594224631786346\n245 0.14768029749393463\n246 0.13993464410305023\n247 0.13263025879859924\n248 0.12566564977169037\n249 0.11907540261745453\n250 0.11283423006534576\n251 0.10694590210914612\n252 0.10133647918701172\n253 0.09602947533130646\n254 0.09101170301437378\n255 0.08625121414661407\n256 0.08174599707126617\n257 0.07748587429523468\n258 0.0734325423836708\n259 0.06960119307041168\n260 0.065968357026577\n261 0.06250457465648651\n262 0.05923768877983093\n263 0.05614769831299782\n264 0.05324922502040863\n265 0.05047252029180527\n266 0.04783950373530388\n267 0.04532942548394203\n268 0.04298963025212288\n269 0.04074981436133385\n270 0.03863658383488655\n271 0.036609236150979996\n272 0.034708935767412186\n273 0.03291018679738045\n274 0.031203722581267357\n275 0.029590697959065437\n276 0.028038157150149345\n277 0.026591498404741287\n278 0.025211861357092857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279 0.023902399465441704\n280 0.02266656421124935\n281 0.021500254049897194\n282 0.020388172939419746\n283 0.01932934857904911\n284 0.0183290783315897\n285 0.017389893531799316\n286 0.01648823171854019\n287 0.01564321666955948\n288 0.014849440194666386\n289 0.014084822498261929\n290 0.01336665078997612\n291 0.012676217593252659\n292 0.012032661586999893\n293 0.011422514915466309\n294 0.010831153020262718\n295 0.010271345265209675\n296 0.009748069569468498\n297 0.009257747791707516\n298 0.008791344240307808\n299 0.00834568589925766\n300 0.007926911115646362\n301 0.007529338821768761\n302 0.007156458217650652\n303 0.0068023353815078735\n304 0.0064567760564386845\n305 0.006137780379503965\n306 0.005835495889186859\n307 0.005543460603803396\n308 0.005271599628031254\n309 0.005017153453081846\n310 0.004775778390467167\n311 0.004540019202977419\n312 0.004319146275520325\n313 0.004110624548047781\n314 0.003915289416909218\n315 0.003723782952874899\n316 0.003548501757904887\n317 0.0033838730305433273\n318 0.003221184480935335\n319 0.0030702969525009394\n320 0.0029247435741126537\n321 0.0027888535987585783\n322 0.002662643324583769\n323 0.0025357676204293966\n324 0.002423624973744154\n325 0.0023154099471867085\n326 0.0022095663007348776\n327 0.0021092367824167013\n328 0.002015066100284457\n329 0.0019278312101960182\n330 0.001841242192313075\n331 0.0017630048096179962\n332 0.0016837436705827713\n333 0.0016115044709295034\n334 0.0015442091971635818\n335 0.0014793415321037173\n336 0.0014162479201331735\n337 0.0013590912567451596\n338 0.0013007097877562046\n339 0.0012477439595386386\n340 0.0011949221370741725"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n341 0.001146554248407483\n342 0.001099910936318338\n343 0.001056428998708725\n344 0.0010135204065591097\n345 0.0009746739524416625\n346 0.0009366651647724211\n347 0.0009000121499411762\n348 0.0008664837223477662\n349 0.0008320668712258339\n350 0.0008017402142286301\n351 0.0007700102287344635\n352 0.0007418421446345747\n353 0.000714151537977159\n354 0.0006870309007354081\n355 0.0006607222021557391\n356 0.0006375958328135312\n357 0.0006143764476291835\n358 0.0005927008460275829\n359 0.0005722892237827182\n360 0.0005509986658580601\n361 0.0005333012668415904\n362 0.0005148581694811583\n363 0.000496857101097703\n364 0.0004793971311300993\n365 0.00046607942203991115\n366 0.0004500332288444042\n367 0.0004342033062130213\n368 0.0004200501716695726\n369 0.0004064659879077226\n370 0.0003941233444493264\n371 0.000381345278583467\n372 0.0003685505944304168\n373 0.0003569947730284184\n374 0.00034597842022776604\n375 0.00033539391006343067\n376 0.0003263033286202699\n377 0.0003158430918119848\n378 0.00030588830122724175\n379 0.00029704091139137745\n380 0.00028784244204871356\n381 0.0002798620262183249\n382 0.00027162773767486215\n383 0.0002638439473230392\n384 0.00025645914138294756\n385 0.00024805497378110886\n386 0.0002415781927993521\n387 0.0002355672768317163\n388 0.00022919292678125203\n389 0.00022273875947576016\n390 0.00021682814985979348\n391 0.00021069143258500844\n392 0.00020514456264209002\n393 0.0001993302721530199\n394 0.00019408896332606673\n395 0.00018897307745646685\n396 0.00018396372615825385\n397 0.00017966986342798918\n398 0.0001744775363476947\n399 0.00017063866835087538\n400 0.00016637535009067506\n401 0.00016290466010104865\n402 0.0001586759608471766\n403"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.00015464704483747482\n404 0.00015143358905334026\n405 0.00014809987624175847\n406 0.00014456186909228563\n407 0.0001408695534337312\n408 0.00013773042883258313\n409 0.0001347492216154933\n410 0.00013184398994781077\n411 0.0001288747735088691\n412 0.00012624355440493673\n413 0.00012318386870902032\n414 0.00011982004798483104\n415 0.0001171897747553885\n416 0.00011481106048449874\n417 0.00011237791477469727\n418 0.00011008457659045234\n419 0.0001074808751582168\n420 0.00010510030551813543\n421 0.00010311800724593922\n422 0.0001009499974315986\n423 9.876683179754764e-05\n424 9.637061884859577e-05\n425 9.445274918107316e-05\n426 9.261509694624692e-05\n427 9.054612746695057e-05\n428 8.889910532161593e-05\n429 8.743000216782093e-05\n430 8.599991997471079e-05\n431 8.439931116299704e-05\n432 8.247123332694173e-05\n433 8.075368532445282e-05\n434 7.939610804896802e-05\n435 7.820792234269902e-05\n436 7.68578247516416e-05\n437 7.512573210988194e-05\n438 7.384310447378084e-05\n439 7.255866512423381e-05\n440 7.09759333403781e-05\n441 6.97629147907719e-05\n442 6.868769560242072e-05\n443 6.767551531083882e-05\n444 6.659477367065847e-05\n445 6.524944910779595e-05\n446 6.396746903192252e-05\n447 6.273790495470166e-05\n448 6.184945959830657e-05\n449 6.076560384826735e-05\n450 5.968872210360132e-05\n451 5.8846497267950326e-05\n452 5.782795778941363e-05\n453 5.707388118025847e-05\n454 5.6246590247610584e-05\n455 5.5078446166589856e-05\n456 5.4263582569547e-05\n457 5.3248117183102295e-05\n458 5.241070539341308e-05\n459 5.1518247346393764e-05\n460"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5.0899463531095535e-05\n461 5.015677379560657e-05\n462 4.9429741920903325e-05\n463 4.874598016613163e-05\n464 4.772334068547934e-05\n465 4.715412433142774e-05\n466 4.6166027459548786e-05\n467 4.564267146633938e-05\n468 4.512797750066966e-05\n469 4.4538828660734e-05\n470 4.3919462768826634e-05\n471 4.327293572714552e-05\n472 4.266794348950498e-05\n473 4.222181814839132e-05\n474 4.161461038165726e-05\n475 4.101153172086924e-05\n476 4.048372647957876e-05\n477 3.968740566051565e-05\n478 3.925956116290763e-05\n479 3.880917211063206e-05\n480 3.8370741094695404e-05\n481 3.776923404075205e-05\n482 3.733004996320233e-05\n483 3.678923167171888e-05\n484 3.618558548623696e-05\n485 3.5894881875719875e-05\n486 3.536084113875404e-05\n487 3.4954093280248344e-05\n488 3.439985812292434e-05\n489 3.39510734193027e-05\n490 3.353260035510175e-05\n491 3.2936612115008757e-05\n492 3.272373214713298e-05\n493 3.228895002393983e-05\n494 3.2041694794315845e-05\n495 3.160213236697018e-05\n496 3.119021494057961e-05\n497 3.063740223296918e-05\n498 3.0377816074178554e-05\n499 2.991824112541508e-05\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class MyReLU(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    We can implement our own custom autograd Functions by subclassing\n",
    "    torch.autograd.Function and implementing the forward and backward passes\n",
    "    which operate on Tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return a\n",
    "        Tensor containing the output. You can cache arbitrary Tensors for use in the\n",
    "        backward pass using the save_for_backward method.\n",
    "        \"\"\"\n",
    "        self.save_for_backward(input)\n",
    "        return input.clamp(min=0)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        input, = self.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input < 0] = 0\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold input and outputs, and wrap them in Variables.\n",
    "x = Variable(torch.randn(N, D_in).type(dtype), requires_grad=False)\n",
    "y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)\n",
    "\n",
    "# Create random Tensors for weights, and wrap them in Variables.\n",
    "w1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=True)\n",
    "w2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Construct an instance of our MyReLU class to use in our network\n",
    "    relu = MyReLU()\n",
    "\n",
    "    # Forward pass: compute predicted y using operations on Variables; we compute\n",
    "    # ReLU using our custom autograd operation.\n",
    "    y_pred = relu(x.mm(w1)).mm(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.data[0])\n",
    "\n",
    "    # Use autograd to compute the backward pass.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    w1.data -= learning_rate * w1.grad.data\n",
    "    w2.data -= learning_rate * w2.grad.data\n",
    "\n",
    "    # Manually zero the gradients after updating weights\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow:Static Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9856e+07\n2.49123e+07\n2.16201e+07\n1.86842e+07\n1.67592e+07\n1.38318e+07\n1.03845e+07\n7.21196e+06\n4.7651e+06\n3.13047e+06\n2.14177e+06\n1.51976e+06\n1.11516e+06\n844736.0\n658784.0\n527306.0\n431536.0\n359744.0\n304381.0\n260735.0\n225520.0\n196636.0\n172544.0\n152174.0\n134769.0\n119786.0\n106795.0\n95451.3"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n85517.7\n76787.2\n69081.4\n62268.0\n56218.5\n50835.5\n46032.5\n41737.3\n37888.5\n34433.9\n31329.3\n28535.1\n26019.8\n23747.5\n21693.6\n19834.5\n18150.2\n16622.6\n15235.5\n13975.4\n12829.2\n11785.0\n10832.7\n9965.76\n9174.08\n8450.34\n7788.32\n7182.51\n6627.73\n6119.2\n5652.49\n5224.19\n4830.47\n4468.41\n4135.53\n3829.0\n3546.81\n3286.81\n3047.16\n2825.98\n2621.87\n2433.37\n2259.37\n2098.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1949.71\n1812.16\n1684.84\n1567.03\n1457.91\n1356.87\n1263.19\n1176.37\n1095.85\n1021.09\n951.699\n887.3\n827.484\n771.908\n720.229\n672.167\n627.583\n586.218\n547.761\n511.935\n478.565\n447.465\n418.485\n391.456\n366.264\n342.752\n320.813\n300.336\n281.219\n263.372\n246.701\n231.123\n216.573"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n202.972\n190.255\n178.362\n167.243\n156.841\n147.113\n138.005\n129.486\n121.509\n114.04\n107.042\n100.49\n94.3578\n88.6107\n83.2216\n78.1697\n73.4366\n68.9987\n64.84\n60.9363\n57.2763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.8414\n50.6185\n47.5942\n44.7554\n42.094\n39.5922\n37.2446\n35.0397\n32.9698\n31.0247\n29.1984\n27.4823\n25.8686\n24.3522\n22.9278\n21.5888\n20.3297\n19.146\n18.0317\n16.9852\n16.0005\n15.0749\n14.2034\n13.3835\n12.6123\n11.8863\n11.203\n10.5606\n9.95593\n9.38567\n8.8495\n8.34403\n7.86884\n7.42067\n6.99839\n6.60117\n6.2264\n5.87323\n5.54176\n5.22886\n4.93372\n4.65542\n4.39327\n4.14616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.91314\n3.69306\n3.48628\n3.29125\n3.10698\n2.9334\n2.76967\n2.61523\n2.46963\n2.33226\n2.2026\n2.07995\n1.9648\n1.85602\n1.75321\n1.65618\n1.56471\n1.47826\n1.39673\n1.31982\n1.24707\n1.17848\n1.11372\n1.05248\n0.994643\n0.940145\n0.88869\n0.839998\n0.794114\n0.750768\n0.709719\n0.670862\n0.634351\n0.599825\n0.567177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536327\n0.507183\n0.479559\n0.453612\n0.429058\n0.405742\n0.383774\n0.363019\n0.343381\n0.324819\n0.307368\n0.290731\n0.275014\n0.260216\n0.246269\n0.23292\n0.22039\n0.208601\n0.197338\n0.186714\n0.176733\n0.167235\n0.158299\n0.149843\n0.141802\n0.134224"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n0.127061\n0.120249\n0.113819\n0.107745\n0.102013\n0.096575\n0.0914119\n0.0865323\n0.0819285\n0.0775756\n0.0734182\n0.0695294\n0.0658258\n0.062359\n0.0590322\n0.0559313\n0.0529726\n0.0501708\n0.0475092\n0.0449911\n0.0426349\n0.0403801\n0.038237\n0.0362041\n0.0343128\n0.0324974\n0.0307873\n0.0291656\n0.0276269\n0.0261735\n0.0248093\n0.0235172\n0.0222807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0211089\n0.0200042\n0.0189486\n0.0179637\n0.0170247\n0.0161458\n0.015303\n0.0145089\n0.0137672\n0.0130463\n0.012377\n0.0117387\n0.0111355\n0.0105595\n0.0100161\n0.00950149\n0.00902056\n0.00855829\n0.00812903\n0.00771913\n0.00732698\n0.00695199\n0.00659939\n0.00626548\n0.00595595\n0.00566005\n0.00537493\n0.0051064\n0.00485294\n0.00461439\n0.00439026\n0.00418028\n0.00397552\n0.0037813\n0.00359863\n0.00342044\n0.00326325\n0.00310441\n0.00296113\n0.00282439\n0.00269136\n0.002564\n0.00244784\n0.00233366\n0.00222497\n0.00212639\n0.00203081\n0.00194004\n0.00185416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00177258\n0.00169252\n0.0016184\n0.00154577\n0.00148094\n0.00141671\n0.00135634\n0.00130047\n0.0012481\n0.00119677\n0.00114479\n0.00109872\n0.00105459\n0.00101399\n0.000972489\n0.000933595\n0.000897712\n0.000863672\n0.000830311\n0.000797681\n0.000767431\n0.000738097\n0.000709394\n0.000682206\n0.000658147\n0.000633164\n0.000609996\n0.000588909\n0.000567683\n0.000548835\n0.000529089\n0.000509893\n0.000491532\n0.000475373\n0.000457972\n0.000444465\n0.000429281\n0.000414114\n0.000399726\n0.000387722\n0.000376184\n0.000363949\n0.000352537\n0.000339775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000328746\n0.000319186\n0.000310045\n0.000300247\n0.000291582\n0.000282931\n0.000274563\n0.000266175\n0.000258383\n0.000251322\n0.000244128\n0.000237014\n0.000230885\n0.000224495\n0.000218742\n0.000212825\n0.000206693\n0.000202212\n0.000196078\n0.000190092\n0.000184668\n0.000179927\n0.000175707\n0.00017139\n0.000167382\n0.000163094\n0.000159321\n0.000154842\n0.000151486\n0.000147903\n0.00014402\n0.000140138\n0.000136796\n0.000133093\n0.000130122\n0.000127236\n0.000124104\n0.000121111\n0.00011875\n0.000116285\n0.000113766\n0.000110594\n0.000108623\n0.000105889\n0.000103455\n0.000101463\n9.94638e-05\n9.73925e-05\n9.4868e-05\n9.28262e-05"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n9.09849e-05\n8.91703e-05\n8.73436e-05\n8.56533e-05\n8.3737e-05\n8.19144e-05\n7.97513e-05\n7.87086e-05\n7.75839e-05\n7.60866e-05\n7.41806e-05\n7.31358e-05\n7.193e-05\n7.03889e-05\n6.91819e-05\n6.7782e-05\n6.6507e-05\n6.55107e-05\n6.44227e-05\n6.34284e-05\n6.21866e-05\n6.09318e-05\n5.99503e-05\n5.92475e-05\n5.82044e-05\n5.73687e-05\n5.62732e-05\n5.5179e-05\n5.42382e-05\n5.30531e-05\n5.22612e-05\n5.12755e-05\n5.03691e-05\n4.93661e-05\n4.8905e-05\n4.82547e-05\n4.75735e-05\n4.67615e-05\n4.59105e-05\n4.54307e-05\n4.47064e-05\n4.41462e-05\n4.33602e-05\n4.29259e-05\n4.20984e-05\n4.1289e-05\n4.07913e-05\n4.0271e-05\n3.94914e-05\n3.9108e-05\n3.83947e-05\n3.80813e-05\n3.73444e-05\n3.66878e-05\n3.61535e-05\n3.57345e-05\n3.50223e-05\n3.46629e-05\n3.41303e-05\n3.35527e-05\n3.32985e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.28799e-05\n3.21972e-05\n3.19172e-05\n3.14288e-05\n3.09897e-05\n3.08119e-05\n3.04481e-05\n3.02571e-05\n2.98197e-05\n2.94273e-05\n2.90781e-05\n2.84546e-05\n2.81965e-05\n2.80055e-05\n2.76259e-05\n2.71091e-05\n2.67577e-05\n2.64695e-05\n2.62394e-05\n2.59903e-05\n2.54857e-05\n2.52779e-05\n2.50456e-05\n2.47805e-05\n2.45081e-05\n2.4156e-05\n2.37818e-05\n2.35647e-05\n2.32609e-05\n2.30599e-05\n2.27844e-05\n2.26089e-05\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# First we set up the computational graph:\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create placeholders for the input and target data; these will be filled\n",
    "# with real data when we execute the graph.\n",
    "x = tf.placeholder(tf.float32, shape=(None, D_in))\n",
    "y = tf.placeholder(tf.float32, shape=(None, D_out))\n",
    "\n",
    "# Create Variables for the weights and initialize them with random data.\n",
    "# A TensorFlow Variable persists its value across executions of the graph.\n",
    "w1 = tf.Variable(tf.random_normal((D_in, H)))\n",
    "w2 = tf.Variable(tf.random_normal((H, D_out)))\n",
    "\n",
    "# Forward pass: Compute the predicted y using operations on TensorFlow Tensors.\n",
    "# Note that this code does not actually perform any numeric operations; it\n",
    "# merely sets up the computational graph that we will later execute.\n",
    "h = tf.matmul(x, w1)\n",
    "h_relu = tf.maximum(h, tf.zeros(1))\n",
    "y_pred = tf.matmul(h_relu, w2)\n",
    "\n",
    "# Compute loss using operations on TensorFlow Tensors\n",
    "loss = tf.reduce_sum((y - y_pred) ** 2.0)\n",
    "\n",
    "# Compute gradient of the loss with respect to w1 and w2.\n",
    "grad_w1, grad_w2 = tf.gradients(loss, [w1, w2])\n",
    "\n",
    "# Update the weights using gradient descent. To actually update the weights\n",
    "# we need to evaluate new_w1 and new_w2 when executing the graph. Note that\n",
    "# in TensorFlow the the act of updating the value of the weights is part of\n",
    "# the computational graph; in PyTorch this happens outside the computational\n",
    "# graph.\n",
    "learning_rate = 1e-6\n",
    "new_w1 = w1.assign(w1 - learning_rate * grad_w1)\n",
    "new_w2 = w2.assign(w2 - learning_rate * grad_w2)\n",
    "\n",
    "# Now we have built our computational graph, so we enter a TensorFlow session to\n",
    "# actually execute the graph.\n",
    "with tf.Session() as sess:\n",
    "    # Run the graph once to initialize the Variables w1 and w2.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Create numpy arrays holding the actual data for the inputs x and targets\n",
    "    # y\n",
    "    x_value = np.random.randn(N, D_in)\n",
    "    y_value = np.random.randn(N, D_out)\n",
    "    for _ in range(500):\n",
    "        # Execute the graph many times. Each time it executes we want to bind\n",
    "        # x_value to x and y_value to y, specified with the feed_dict argument.\n",
    "        # Each time we execute the graph we want to compute the values for loss,\n",
    "        # new_w1, and new_w2; the values of these Tensors are returned as numpy\n",
    "        # arrays.\n",
    "        loss_value, _, _ = sess.run([loss, new_w1, new_w2],\n",
    "                                    feed_dict={x: x_value, y: y_value})\n",
    "        print(loss_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch:nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 682.967529296875\n1 633.0652465820312\n2 589.8352661132812\n3 552.0377807617188\n4 518.4387817382812\n5 487.92449951171875\n6 460.17291259765625\n7 434.44293212890625\n8 410.5075988769531\n9 388.10162353515625\n10 367.1235656738281\n11 347.4091796875\n12 328.82177734375\n13 311.3520202636719\n14 294.80987548828125\n15 279.11712646484375\n16 264.2137451171875\n17 250.06900024414062\n18 236.58885192871094\n19 223.74049377441406\n20 211.49725341796875\n21 199.86253356933594\n22 188.8033905029297\n23 178.31637573242188\n24 168.32505798339844\n25 158.83262634277344\n26 149.8106231689453\n27 141.2534942626953\n28 133.13661193847656\n29 125.46305847167969\n30 118.18266296386719\n31 111.28265380859375\n32 104.74330139160156\n33 98.56596374511719\n34 92.7420425415039\n35 87.23712921142578\n36 82.0274658203125\n37 77.11185455322266\n38 72.4767074584961\n39 68.11331176757812\n40"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64.00308227539062\n41 60.13591003417969\n42 56.49797058105469\n43 53.0745735168457\n44 49.8572883605957\n45 46.84135818481445\n46 44.013851165771484\n47 41.3612060546875\n48 38.87284851074219\n49 36.54164123535156\n50 34.35846710205078\n51 32.31317901611328\n52 30.393863677978516\n53 28.595706939697266\n54 26.915088653564453\n55 25.338285446166992\n56 23.86078643798828\n57 22.473798751831055\n58 21.173381805419922\n59 19.95696258544922\n60 18.8155517578125\n61 17.743804931640625\n62 16.73636817932129\n63 15.79076099395752\n64 14.90360164642334\n65 14.070524215698242\n66 13.289501190185547\n67 12.556434631347656\n68 11.86719799041748\n69 11.218164443969727\n70 10.60930347442627\n71 10.036059379577637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 9.497588157653809\n73 8.989448547363281\n74 8.510945320129395\n75 8.06060791015625\n76 7.6363630294799805\n77 7.236481189727783\n78 6.859354496002197\n79 6.503286361694336\n80 6.167531490325928\n81 5.852107524871826\n82 5.554301738739014\n83 5.272947788238525\n84 5.007266998291016\n85 4.755927562713623\n86 4.518645286560059\n87 4.294075965881348\n88 4.081783294677734\n89 3.8810007572174072\n90 3.690610647201538\n91 3.5103414058685303\n92 3.340005397796631\n93 3.178680658340454\n94 3.025718927383423\n95 2.8807451725006104\n96 2.7431142330169678\n97 2.612151622772217\n98 2.4878270626068115\n99 2.3699612617492676\n100 2.258089780807495\n101 2.1518659591674805\n102 2.050945520401001\n103 1.9553142786026\n104 1.8646584749221802\n105 1.778742790222168\n106 1.6972219944000244\n107 1.6196749210357666\n108 1.5459181070327759\n109 1.4758198261260986\n110 1.4091588258743286\n111 1.345731496810913\n112 1.2853645086288452\n113 1.2280460596084595\n114 1.1736146211624146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 1.1217564344406128\n116 1.072189450263977\n117 1.0249203443527222\n118 0.9799579977989197\n119 0.9370840787887573\n120 0.8963528871536255\n121 0.8574369549751282\n122 0.820303738117218\n123 0.7849448323249817\n124 0.7511739134788513\n125 0.7189729809761047\n126 0.6882777214050293\n127 0.6589100360870361\n128 0.6308767795562744\n129 0.6041113138198853\n130 0.5785759687423706\n131 0.5541542172431946\n132 0.5308406949043274\n133 0.5085663199424744\n134 0.4872720241546631\n135 0.46694570779800415\n136 0.447537899017334\n137 0.42900535464286804\n138 0.4112616181373596\n139 0.3942968249320984\n140 0.3780837655067444\n141 0.3625902235507965\n142 0.34775763750076294\n143 0.333577960729599\n144 0.3200100362300873\n145 0.30702346563339233\n146 0.29459092020988464\n147 0.2826943099498749\n148 0.271307110786438\n149 0.26040196418762207\n150 0.24995951354503632\n151 0.23996670544147491\n152 0.23038724064826965\n153 0.22121064364910126\n154 0.21241231262683868\n155 0.20398971438407898\n156 0.19591622054576874\n157 0.18817448616027832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 0.18076084554195404\n159 0.17364852130413055\n160 0.16683542728424072\n161 0.16030260920524597\n162 0.1540360003709793\n163 0.1480337679386139\n164 0.1422741413116455\n165 0.1367524117231369\n166 0.13145451247692108\n167 0.1263682246208191\n168 0.12149247527122498\n169 0.11681119352579117\n170 0.11231840401887894\n171 0.10800463706254959\n172 0.10386580973863602\n173 0.09989293664693832\n174 0.09607913345098495\n175 0.0924183651804924\n176 0.08890185505151749\n177 0.08552704751491547\n178 0.08228594809770584\n179 0.07916904240846634\n180 0.07617808133363724\n181 0.07330349832773209\n182 0.07054453343153\n183 0.06789617985486984\n184 0.06534910947084427\n185 0.06289897114038467\n186 0.06054665520787239\n187 0.058288149535655975\n188 0.05611554533243179\n189 0.054027192294597626\n190 0.05202015861868858\n191 0.050090812146663666\n192 0.04823624715209007\n193 0.04645414277911186\n194 0.04474150761961937\n195 0.0430927611887455\n196 0.04150776565074921\n197 0.03998245671391487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198 0.03851410374045372\n199 0.03710298612713814\n200 0.035747576504945755\n201 0.03444236144423485\n202 0.033186763525009155\n203 0.03197731822729111\n204 0.03081558272242546\n205 0.029697872698307037\n206 0.028620947152376175\n207 0.027585124596953392\n208 0.026588642969727516\n209 0.0256288331001997\n210 0.02470538206398487\n211 0.023816455155611038\n212 0.022960275411605835\n213 0.02213692106306553\n214 0.021343199536204338\n215 0.020579872652888298\n216 0.019844507798552513\n217 0.019136153161525726\n218 0.018453745171427727\n219 0.017796987667679787\n220 0.01716441474854946\n221 0.0165546964854002\n222 0.015967637300491333\n223 0.015402205288410187\n224 0.014858526177704334\n225 0.014334115199744701\n226 0.01382889598608017\n227 0.013341917656362057\n228 0.012872125022113323\n229 0.012419984675943851\n230 0.011984746903181076\n231 0.011564694344997406\n232 0.011160116642713547\n233 0.010770001448690891\n234 0.010393588803708553\n235 0.010031074285507202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236 0.00968189351260662\n237 0.009345049038529396\n238 0.009021204896271229\n239 0.008708411827683449\n240 0.00840712059289217\n241 0.008116574957966805\n242 0.007836421951651573\n243 0.007566316518932581\n244 0.0073058451525866985\n245 0.00705452635884285\n246 0.0068122693337500095\n247 0.0065788161009550095\n248 0.006353468168526888\n249 0.006136229261755943\n250 0.0059265573509037495\n251 0.005724351387470961\n252 0.005529290065169334\n253 0.005340916570276022\n254 0.005159234162420034\n255 0.00498412549495697\n256 0.0048151081427931786\n257 0.00465221656486392\n258 0.004494701977819204\n259 0.0043426998890936375\n260 0.004195960704237223\n261 0.004054475575685501\n262 0.003917780704796314\n263 0.0037862085737288\n264 0.003659152891486883\n265 0.0035363805945962667\n266 0.00341772916726768\n267 0.0033032274805009365\n268 0.003192645264789462\n269 0.0030858898535370827\n270 0.0029829363338649273\n271 0.0028835556004196405\n272 0.0027874980587512255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273 0.002694701077416539\n274 0.0026050785090774298\n275 0.0025185877457261086\n276 0.0024351670872420073\n277 0.002354520373046398\n278 0.0022765439935028553\n279 0.0022012810222804546\n280 0.0021286525297909975\n281 0.0020584396552294493\n282 0.0019905546214431524\n283 0.0019249790348112583\n284 0.0018616619054228067\n285 0.001800514874048531\n286 0.0017413997557014227\n287 0.0016843831399455667\n288 0.001629235572181642\n289 0.001575956353917718\n290 0.0015245089307427406\n291 0.001474714488722384\n292 0.001426617382094264\n293 0.0013800672022625804\n294 0.001335112378001213\n295 0.0012917319545522332\n296 0.0012497553834691644\n297 0.0012091826647520065\n298 0.0011699512833729386\n299 0.0011320651974529028\n300 0.0010954133467748761\n301 0.00105999072548002\n302 0.0010257905814796686\n303 0.000992716639302671\n304 0.0009607896208763123\n305 0.000929857196751982\n306 0.0008999188430607319\n307 0.0008709814283065498\n308 0.0008430116577073932\n309 0.000815952371340245\n310"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0007897952455095947\n311 0.0007644780562259257\n312 0.0007400367176160216\n313 0.0007163746049627662\n314 0.0006934813573025167\n315 0.0006713385810144246\n316 0.000649926601909101\n317 0.0006292270263656974\n318 0.0006092306575737894\n319 0.0005898579838685691\n320 0.0005711329285986722\n321 0.0005529894260689616\n322 0.0005354451132006943\n323 0.000518482644110918\n324 0.000502082402817905\n325 0.00048622244503349066\n326 0.00047086633276194334\n327 0.00045598557335324585\n328 0.000441591051639989\n329 0.00042766216211020947\n330 0.0004141897370573133\n331 0.00040115980664268136\n332 0.0003885275509674102\n333 0.0003763212589547038\n334 0.0003645272518042475\n335 0.0003530859248712659\n336 0.00034200894879177213\n337 0.00033129978692159057\n338 0.00032092505716718733\n339 0.00031088784453459084\n340 0.0003011756343767047\n341 0.00029177512624301016\n342 0.00028268207097426057\n343 0.00027387362206354737\n344 0.00026535525103099644\n345 0.0002570949727669358\n346 0.0002490958431735635\n347 0.00024135249259416014\n348 0.0002338586637051776\n349 0.00022661079128738493\n350 0.00021959505102131516\n351 0.00021279312204569578\n352 0.00020619724818971008\n353 0.00019980929209850729\n354 0.00019363405590411276\n355 0.00018765393178910017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356 0.00018187605019193143\n357 0.00017627302440814674\n358 0.00017083271814044565\n359 0.00016556902846787125\n360 0.00016047392273321748\n361 0.0001555424532853067\n362 0.00015076366253197193\n363 0.00014613896200899035\n364 0.00014165286847855896\n365 0.00013731162471231073\n366 0.00013310388021636754\n367 0.00012902749585919082\n368 0.0001250818168045953\n369 0.00012125993089284748\n370 0.00011755601008189842\n371 0.00011396463378332555\n372 0.0001104821203625761\n373 0.00010711324284784496\n374 0.00010385036875959486\n375 0.00010069286508951336\n376 9.762676199898124e-05\n377 9.465646871831268e-05\n378 9.177981701213866e-05\n379 8.899001841200516e-05\n380 8.62869419506751e-05\n381 8.367545524379238e-05\n382 8.114306547213346e-05\n383 7.868399552535266e-05\n384 7.630173058714718e-05\n385 7.399277819786221e-05\n386 7.175243081292138e-05\n387 6.958514131838456e-05\n388 6.74845214234665e-05\n389 6.544963252963498e-05\n390 6.34736061329022e-05\n391 6.156111339805648e-05\n392 5.971021164441481e-05\n393 5.7913402997655794e-05\n394 5.6169232266256586e-05\n395 5.447608054964803e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396 5.283781865728088e-05\n397 5.125462485011667e-05\n398 4.971573798684403e-05\n399 4.822614209842868e-05\n400 4.678145342040807e-05\n401 4.5378350478131324e-05\n402 4.4022235670126975e-05\n403 4.269992496119812e-05\n404 4.1427414544159546e-05\n405 4.0188675484387204e-05\n406 3.8983944250503555e-05\n407 3.782057683565654e-05\n408 3.66916719940491e-05\n409 3.559609831427224e-05\n410 3.4535489248810336e-05\n411 3.350585757289082e-05\n412 3.25086475641001e-05\n413 3.1537605536868796e-05\n414 3.060111703234725e-05\n415 2.96922280540457e-05\n416 2.8807367925764993e-05\n417 2.7950907679041848e-05\n418 2.7124224288854748e-05\n419 2.631877941894345e-05\n420 2.5537112378515303e-05\n421 2.478236456227023e-05\n422 2.404611586825922e-05\n423 2.3333257558988407e-05\n424 2.263992791995406e-05\n425 2.1972355170873925e-05\n426 2.1322124666767195e-05\n427 2.069214497169014e-05\n428 2.0081473849131726e-05\n429 1.9487548343022354e-05\n430 1.8911454390035942e-05\n431 1.835491093515884e-05\n432 1.7813268641475588e-05\n433 1.7288015442318283e-05\n434 1.6777317796368152e-05\n435 1.6283367585856467e-05\n436 1.5805706425453536e-05\n437 1.5340989193646237e-05\n438 1.4889775229676161e-05\n439 1.4452313735091593e-05\n440 1.402625821356196e-05\n441 1.361463000648655e-05\n442 1.3215070794103667e-05\n443 1.2826919373765122e-05\n444 1.2452242117433343e-05\n445 1.2086752576578874e-05\n446 1.1732552593457513e-05\n447 1.1387875019863714e-05\n448 1.1054130482079927e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449 1.073139992513461e-05\n450 1.0416625627840403e-05\n451 1.0111839401361067e-05\n452 9.816954843699932e-06\n453 9.529985618428327e-06\n454 9.250646144209895e-06\n455 8.980847269413061e-06\n456 8.719417564861942e-06\n457 8.463855920126662e-06\n458 8.218104994739406e-06\n459 7.978141184139531e-06\n460 7.744959475530777e-06\n461 7.520170129282633e-06\n462 7.30241981727886e-06\n463 7.0884461820241995e-06\n464 6.88270665705204e-06\n465 6.682048478978686e-06\n466 6.4871078393480275e-06\n467 6.299737378867576e-06\n468 6.116234544606414e-06\n469 5.9377384786785115e-06\n470 5.766095000581117e-06\n471 5.598069947154727e-06\n472 5.4363617891795e-06\n473 5.278116532281274e-06\n474 5.126251380715985e-06\n475 4.977256594429491e-06\n476 4.832588729186682e-06\n477 4.693336904892931e-06\n478 4.556743078865111e-06\n479 4.425023234944092e-06\n480 4.297058694646694e-06\n481 4.172988155914936e-06\n482 4.05173977924278e-06\n483 3.935198947147001e-06\n484 3.821343398158206e-06\n485 3.711072167789098e-06\n486 3.604598987294594e-06\n487 3.5002638014702825e-06\n488 3.399644128876389e-06\n489 3.3009287108143326e-06\n490 3.2052935239335056e-06\n491 3.1129916351346765e-06\n492 3.0231856271711877e-06\n493 2.936136979769799e-06\n494 2.8511449272627942e-06\n495 2.7692919957189588e-06\n496 2.689915618248051e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497 2.6126015200134134e-06\n498 2.537262616897351e-06\n499 2.4643786673550494e-06\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs, and wrap them in Variables.\n",
    "x = Variable(torch.randn(N, D_in))\n",
    "y = Variable(torch.randn(N, D_out), requires_grad=False)\n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. Each Linear Module computes output from input using a\n",
    "# linear function, and holds internal Variables for its weight and bias.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "\n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
    "    # override the __call__ operator so you can call them like functions. When\n",
    "    # doing so you pass a Variable of input data to the Module and it produces\n",
    "    # a Variable of output data.\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss. We pass Variables containing the predicted and true\n",
    "    # values of y, and the loss function returns a Variable containing the\n",
    "    # loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(t, loss.data[0])\n",
    "\n",
    "    # Zero the gradients before running the backward pass.\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
    "    # parameters of the model. Internally, the parameters of each Module are stored\n",
    "    # in Variables with requires_grad=True, so this call will compute gradients for\n",
    "    # all learnable parameters in the model.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights using gradient descent. Each parameter is a Variable, so\n",
    "    # we can access its data and gradients like we did before.\n",
    "    for param in model.parameters():\n",
    "        param.data -= learning_rate * param.grad.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch:optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 641.1871948242188\n1 624.4564208984375\n2 608.2522583007812\n3 592.5743408203125\n4 577.3336791992188\n5 562.553466796875\n6 548.1904296875\n7 534.2842407226562\n8 520.7975463867188\n9 507.67059326171875\n10 494.985595703125\n11 482.7084045410156\n12 470.75518798828125\n13 459.1197509765625\n14 447.87432861328125\n15 436.9541320800781\n16 426.3272705078125\n17 416.006103515625\n18 405.96990966796875\n19 396.2611083984375\n20 386.8105163574219\n21 377.6636047363281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 368.7762451171875\n23 360.1962890625\n24 351.8753356933594\n25 343.7672119140625\n26 335.8818664550781\n27 328.21630859375\n28 320.7347717285156\n29 313.43768310546875\n30 306.3140563964844\n31 299.3489074707031\n32 292.53192138671875\n33 285.8869323730469\n34 279.405029296875\n35 273.0564880371094\n36 266.8760986328125\n37 260.7981262207031\n38 254.83253479003906\n39 249.00071716308594\n40 243.3070831298828\n41 237.73997497558594\n42 232.2718505859375\n43 226.91622924804688\n44 221.6835479736328\n45 216.56590270996094\n46 211.5280303955078\n47"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 206.57713317871094\n48 201.7186737060547\n49 196.95632934570312\n50 192.30467224121094\n51 187.74224853515625\n52 183.27261352539062\n53 178.90182495117188\n54 174.62623596191406\n55 170.43441772460938\n56 166.3224334716797\n57 162.2825164794922\n58 158.3136444091797\n59 154.420166015625\n60 150.61318969726562\n61 146.8853759765625\n62 143.22605895996094\n63 139.63351440429688\n64 136.11685180664062\n65 132.67001342773438\n66 129.28550720214844\n67 125.97191619873047\n68 122.71893310546875\n69 119.51490020751953\n70 116.37101745605469\n71 113.2924575805664\n72 110.27171325683594\n73 107.30476379394531\n74 104.39315032958984\n75 101.54102325439453\n76 98.74989318847656\n77 96.02059936523438\n78 93.34642791748047\n79 90.73096466064453\n80 88.17081451416016\n81 85.6627426147461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 83.21097564697266\n83 80.80750274658203\n84 78.45838165283203\n85 76.16474151611328\n86 73.9245834350586\n87 71.73482513427734\n88 69.59273529052734\n89 67.50202941894531\n90 65.45854949951172\n91 63.46892166137695\n92 61.5222053527832\n93 59.61642074584961\n94 57.75416564941406\n95 55.940284729003906\n96 54.168758392333984\n97 52.43913650512695\n98 50.74849319458008\n99 49.100929260253906\n100 47.49281692504883\n101 45.9290771484375\n102 44.40837860107422\n103 42.926429748535156\n104 41.48394775390625\n105 40.082862854003906\n106 38.718040466308594\n107 37.3907585144043\n108 36.100643157958984\n109 34.845802307128906\n110 33.62739562988281\n111 32.44354248046875\n112 31.294492721557617\n113 30.1794376373291\n114 29.099042892456055\n115 28.051000595092773\n116 27.034244537353516\n117 26.04847526550293\n118 25.09476661682129\n119 24.17011833190918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 23.274673461914062\n121 22.405946731567383\n122 21.564741134643555\n123 20.74894905090332\n124 19.95897102355957\n125 19.19451904296875\n126 18.455869674682617\n127 17.74089813232422\n128 17.05150032043457\n129 16.384456634521484\n130 15.741168975830078\n131 15.121050834655762\n132 14.52238941192627\n133 13.945876121520996\n134 13.38987922668457\n135 12.855070114135742\n136 12.340188980102539\n137 11.845571517944336\n138 11.369613647460938\n139 10.911545753479004\n140 10.471378326416016\n141 10.048380851745605\n142 9.64028263092041\n143 9.248909950256348\n144 8.873111724853516\n145 8.511734008789062\n146 8.164649963378906\n147 7.831090927124023\n148 7.510732650756836\n149 7.20302152633667\n150 6.908015251159668\n151 6.625031471252441\n152 6.353613376617432\n153 6.093395233154297\n154 5.84392786026001\n155 5.604739665985107\n156 5.375487804412842\n157 5.155955791473389\n158 4.945859432220459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159 4.744379043579102\n160 4.551458358764648\n161 4.3668212890625\n162 4.190115928649902\n163 4.021347522735596\n164 3.859665870666504\n165 3.7049412727355957\n166 3.5568606853485107\n167 3.4153103828430176\n168 3.280189275741577\n169 3.1505510807037354\n170 3.0267724990844727\n171 2.9082837104797363\n172 2.7950592041015625\n173 2.686544895172119\n174 2.582766056060791\n175 2.4834680557250977\n176 2.3884811401367188\n177 2.2973146438598633\n178 2.2100062370300293\n179 2.1263444423675537\n180 2.0462534427642822\n181 1.9695361852645874\n182 1.8960858583450317\n183 1.8256711959838867\n184 1.7582138776779175\n185 1.6935948133468628\n186 1.631697177886963\n187 1.5723681449890137\n188 1.5154978036880493\n189 1.4609923362731934\n190 1.4087475538253784\n191 1.3586523532867432\n192"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.310606598854065\n193 1.2645126581192017\n194 1.2202740907669067\n195 1.1779241561889648\n196 1.1372895240783691\n197 1.0982683897018433\n198 1.0608115196228027\n199 1.024768352508545\n200 0.9901505708694458\n201 0.9568563103675842\n202 0.9248519539833069\n203 0.894030749797821\n204 0.8644475340843201\n205 0.8359284996986389\n206 0.8084863424301147\n207 0.7820603251457214\n208 0.7565983533859253\n209 0.7320371866226196\n210 0.7083682417869568\n211 0.685537576675415\n212 0.6635079979896545\n213 0.6422497630119324\n214 0.6217361092567444\n215 0.6019290685653687\n216 0.5828129649162292\n217 0.564304530620575\n218 0.5464428663253784\n219 0.529183030128479\n220 0.5124674439430237\n221 0.4963180720806122\n222 0.48070040345191956\n223 0.46556857228279114\n224 0.4509354531764984\n225 0.43676748871803284\n226 0.42304810881614685\n227 0.4097602665424347\n228 0.3968876898288727\n229 0.3844127953052521\n230 0.3723279535770416\n231 0.36061835289001465\n232 0.3492695689201355\n233 0.338265597820282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234 0.3275966942310333\n235 0.31725403666496277\n236 0.3072243332862854\n237 0.2974972724914551\n238 0.28806307911872864\n239 0.27891242504119873\n240 0.2700342535972595\n241 0.2614229619503021\n242 0.25306636095046997\n243 0.24496150016784668\n244 0.23709779977798462\n245 0.2294662743806839\n246 0.22206321358680725\n247 0.21488414704799652\n248 0.2079235166311264\n249 0.2011699229478836\n250 0.19461743533611298\n251 0.18825985491275787\n252 0.1820906549692154\n253 0.17610624432563782\n254 0.17029909789562225\n255 0.16466645896434784\n256 0.15920394659042358\n257 0.15390361845493317\n258 0.14876270294189453\n259 0.14377637207508087\n260 0.13894009590148926\n261 0.13425005972385406\n262 0.12970155477523804\n263 0.12529195845127106\n264 0.1210165023803711\n265 0.11687137931585312\n266 0.11285290867090225\n267 0.10895804315805435\n268 0.1051829382777214\n269 0.10152478516101837\n270 0.09798058867454529\n271 0.09454712271690369\n272 0.09121990948915482\n273 0.08799761533737183\n274 0.08487710356712341\n275 0.08185523748397827\n276 0.07892923802137375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277 0.07609657943248749\n278 0.07335448265075684\n279 0.07070086896419525\n280 0.06813257187604904\n281 0.06564813107252121\n282 0.06324407458305359\n283 0.06091928854584694\n284 0.05867033079266548\n285 0.056495774537324905\n286 0.054393619298934937\n287 0.05236119031906128\n288 0.050396669656038284\n289 0.04849838465452194\n290 0.04666416347026825\n291 0.0448923334479332\n292 0.04318052530288696\n293 0.041527457535266876\n294 0.0399317666888237\n295 0.03839060664176941\n296 0.03690332919359207\n297 0.03546787425875664\n298 0.034082815051078796\n299 0.03274661675095558\n300 0.03145742416381836\n301 0.03021433763206005\n302 0.029015645384788513\n303 0.027859967201948166\n304 0.026745960116386414\n305 0.02567220851778984\n306 0.02463771030306816\n307 0.023641033098101616\n308 0.02268177643418312\n309 0.021757900714874268\n310 0.020868288353085518\n311 0.020011788234114647\n312 0.019187280908226967\n313 0.018393833190202713\n314 0.01763409934937954\n315 0.016905441880226135\n316 0.01620476506650448\n317 0.015530850738286972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318 0.0148830097168684\n319 0.014260156080126762\n320 0.013661529868841171\n321 0.013086196035146713\n322 0.012533272616565228\n323 0.012002239935100079\n324 0.01149226725101471\n325 0.011002411134541035\n326 0.010532062500715256\n327 0.010080316103994846\n328 0.009646662510931492\n329 0.009230484254658222\n330 0.008831010200083256\n331 0.008447729051113129\n332 0.008080963976681232\n333 0.007729141041636467\n334 0.00739155150949955\n335 0.007067900616675615\n336 0.006757454015314579\n337 0.0064598266035318375\n338 0.006174502428621054\n339 0.005901002790778875\n340 0.00563879543915391\n341 0.005387535318732262\n342 0.005150997079908848\n343 0.004925608169287443\n344 0.004709812346845865\n345 0.004503128118813038\n346 0.004305234178900719\n347 0.0041157398372888565\n348 0.0039343032985925674\n349 0.003760612802579999\n350 0.003594323294237256\n351 0.0034351360518485308\n352 0.003282686462625861\n353 0.003136739367619157\n354 0.002997055184096098\n355 0.002863232046365738\n356"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.002735139336436987\n357 0.0026125088334083557\n358 0.002495106542482972\n359 0.002382679609581828\n360 0.0022750806529074907\n361 0.0021720565855503082\n362 0.00207345187664032\n363 0.001979082589969039\n364 0.001888749422505498\n365 0.001802342478185892\n366 0.001719645457342267\n367 0.0016405213391408324\n368 0.0015648294938728213\n369 0.0014924758579581976\n370 0.0014232378453016281\n371 0.001357050845399499\n372 0.0012937681749463081\n373 0.001233270508237183\n374 0.0011754459701478481\n375 0.0011202169116586447\n376 0.001067435834556818\n377 0.0010170107707381248\n378 0.0009688560967333615\n379 0.0009228652343153954\n380 0.0008789353305473924\n381 0.0008370163850486279\n382 0.000796972424723208\n383 0.000758751411922276\n384 0.0007223032298497856\n385 0.0006874841055832803\n386 0.0006542862975038588\n387 0.0006226164405234158\n388 0.0005924035212956369\n389 0.0005635897978208959\n390 0.0005361033254303038\n391 0.0005098901456221938\n392 0.0004849062825087458\n393 0.000461091025499627\n394 0.00043839483987540007\n395 0.0004167590232100338\n396 0.000396137242205441\n397 0.0003764921857509762\n398 0.00035776669392362237\n399 0.0003399475244805217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 0.00032296855351887643\n401 0.0003068032383453101\n402 0.0002913972130045295\n403 0.00027673906879499555\n404 0.0002627770882099867\n405 0.0002494918298907578\n406 0.0002368540590396151\n407 0.0002248156670248136\n408 0.00021337179350666702\n409 0.0002024760324275121\n410 0.00019212100596632808\n411 0.00018226105021312833\n412 0.00017289654351770878\n413 0.00016398722073063254\n414 0.00015552609693259\n415 0.00014746403030585498\n416 0.00013981005758978426\n417 0.00013254323857836425\n418 0.00012563285417854786\n419 0.00011906620056834072\n420 0.0001128253061324358\n421 0.00010690831550164148\n422 0.00010127094719791785\n423 9.5938186859712e-05\n424 9.086540376301855e-05\n425 8.60465006553568e-05\n426 8.147615153575316e-05\n427 7.714173261774704e-05\n428 7.302535232156515e-05\n429 6.912498793099076e-05\n430 6.54138348181732e-05\n431 6.190606654854491e-05\n432 5.85694178880658e-05\n433 5.541340942727402e-05\n434 5.240928294369951e-05\n435 4.957428609486669e-05\n436 4.6877539716660976e-05\n437 4.432810237631202e-05\n438 4.190738036413677e-05\n439 3.9614675188204274e-05\n440 3.744527930393815e-05\n441 3.5386452509555966e-05\n442 3.343515345477499e-05\n443 3.159317566314712e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444 2.984488855872769e-05\n445 2.8187994757900015e-05\n446 2.662612678250298e-05\n447 2.514143125154078e-05\n448 2.3736603907309473e-05\n449 2.2412214093492366e-05\n450 2.1153002307983115e-05\n451 1.996442188101355e-05\n452 1.8841421479010023e-05\n453 1.77770580194192e-05\n454 1.6774039977462962e-05\n455 1.582378172315657e-05\n456 1.4924420611350797e-05\n457 1.4074718819756526e-05\n458 1.3270152521727141e-05\n459 1.2512186913227197e-05\n460 1.1794232705142349e-05\n461 1.1118176189484075e-05\n462 1.0478589501872193e-05\n463 9.874055649561342e-06\n464 9.302093531005085e-06\n465 8.764875019551255e-06\n466 8.255692591774277e-06\n467 7.775726771797054e-06\n468 7.321582415897865e-06\n469 6.894387752254261e-06\n470 6.4921468947432e-06\n471 6.109266905696131e-06\n472 5.751155640609795e-06\n473 5.411930487753125e-06\n474 5.092917490401305e-06\n475 4.791046649188502e-06\n476 4.505915967456531e-06\n477 4.238464043737622e-06\n478 3.9862147787061986e-06\n479 3.747644768736791e-06\n480 3.52282131643733e-06\n481 3.3126375456049573e-06\n482 3.113010279776063e-06\n483 2.9259558687044773e-06\n484 2.74856529358658e-06\n485 2.582456545496825e-06\n486 2.4260061763925478e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487 2.2795145468990086e-06\n488 2.139767047992791e-06\n489 2.009692252613604e-06\n490 1.887005964817945e-06\n491 1.770929657141096e-06\n492 1.662801651036716e-06\n493 1.5595279592162115e-06\n494 1.4636567584602744e-06\n495 1.3733656487602275e-06\n496 1.2882155715487897e-06\n497 1.208472895086743e-06\n498 1.1334969940435258e-06\n499 1.0626855555528891e-06\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs, and wrap them in Variables.\n",
    "x = Variable(torch.randn(N, D_in))\n",
    "y = Variable(torch.randn(N, D_out), requires_grad=False)\n",
    "\n",
    "# Use the nn package to define our model and loss function.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "# Use the optim package to define an Optimizer that will update the weights of\n",
    "# the model for us. Here we will use Adam; the optim package contains many other\n",
    "# optimization algoriths. The first argument to the Adam constructor tells the\n",
    "# optimizer which Variables it should update.\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(t, loss.data[0])\n",
    "\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable weights\n",
    "    # of the model)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch:Custom nn Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 643.8016967773438\n1 598.0394287109375\n2 558.4880981445312\n3 523.610595703125\n4 492.3335266113281\n5 464.1885681152344\n6 438.6236877441406\n7 415.15472412109375\n8 393.5523376464844\n9 373.26519775390625\n10 354.255859375\n11 336.38946533203125\n12 319.50250244140625\n13 303.4895935058594\n14 288.31842041015625\n15 273.9407043457031\n16 260.2964172363281\n17 247.318603515625\n18 234.9268341064453\n19 223.0648956298828\n20 211.7288360595703\n21 200.91957092285156\n22 190.58250427246094\n23 180.7069549560547\n24 171.19155883789062\n25 162.1077423095703\n26 153.4598846435547\n27 145.2414093017578\n28 137.37799072265625\n29 129.8969268798828\n30 122.77344512939453\n31 116.01669311523438\n32 109.57743835449219\n33 103.466796875\n34 97.67986297607422\n35 92.18344116210938\n36 86.96871948242188\n37 82.03437042236328\n38 77.37037658691406\n39 72.97197723388672\n40 68.81708526611328\n41 64.90400695800781\n42 61.21097946166992\n43 57.72698974609375\n44 54.440452575683594\n45 51.35317611694336\n46 48.4455451965332\n47 45.70756530761719\n48 43.131797790527344\n49 40.71266174316406\n50 38.433109283447266\n51 36.28737258911133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 34.26923751831055\n53 32.37336730957031\n54 30.591148376464844\n55 28.91615867614746\n56 27.338462829589844\n57 25.853761672973633\n58 24.457359313964844\n59 23.14542007446289\n60 21.911405563354492\n61 20.75019645690918\n62 19.657861709594727\n63 18.626922607421875\n64 17.65589141845703\n65 16.741487503051758\n66 15.877389907836914\n67 15.062808990478516\n68 14.29263973236084\n69 13.564659118652344\n70 12.876704216003418\n71 12.227102279663086\n72 11.6142578125\n73 11.034729957580566\n74 10.4865083694458\n75 9.968419075012207\n76 9.478012084960938\n77 9.01500129699707\n78 8.576364517211914\n79 8.161737442016602\n80 7.769583225250244\n81 7.398762226104736\n82 7.046533584594727\n83 6.7128825187683105\n84 6.39616584777832\n85 6.0960540771484375\n86 5.8115739822387695\n87 5.54143762588501\n88 5.285310745239258\n89 5.0408616065979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 4.809054374694824\n91 4.589075565338135\n92 4.379992485046387\n93 4.180983066558838\n94 3.9919307231903076\n95 3.8123345375061035\n96 3.6415252685546875\n97 3.479006052017212\n98 3.324462413787842\n99 3.177361488342285\n100 3.0372567176818848\n101 2.903874397277832\n102 2.776740312576294\n103 2.6556050777435303\n104 2.540282726287842\n105 2.4302525520324707\n106 2.325394868850708\n107 2.2255520820617676\n108 2.130370855331421\n109 2.0395894050598145\n110 1.9529868364334106\n111 1.8703316450119019\n112 1.7914011478424072\n113 1.7160979509353638\n114 1.6442538499832153\n115 1.5756685733795166\n116 1.5101810693740845\n117 1.4477198123931885\n118 1.388108730316162\n119 1.331147313117981\n120 1.2766997814178467\n121 1.2246732711791992\n122 1.1748887300491333\n123 1.1272979974746704\n124 1.0817785263061523\n125 1.0382691621780396\n126 0.9966469407081604\n127 0.9567820429801941\n128 0.9186995029449463\n129 0.8822503089904785\n130 0.8474072813987732\n131 0.8140659332275391\n132 0.7821127772331238\n133 0.7515081763267517\n134"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.7221991419792175\n135 0.6941154599189758\n136 0.6672132015228271\n137 0.6414446830749512\n138 0.6167176365852356\n139 0.5930198431015015\n140 0.5703443884849548\n141 0.5485801696777344\n142 0.5277153253555298\n143 0.5077037811279297\n144 0.4884834885597229\n145 0.4700517952442169\n146 0.452357679605484\n147 0.4353726804256439\n148 0.41905224323272705\n149 0.40339788794517517\n150 0.3883403241634369\n151 0.3738848865032196\n152 0.3600112199783325\n153 0.3466835916042328\n154 0.333869993686676\n155 0.3215627074241638\n156 0.30974170565605164\n157 0.2983769178390503\n158 0.28745123744010925\n159 0.2769524157047272\n160 0.2668653726577759\n161 0.2571691870689392\n162 0.24784478545188904\n163 0.23887035250663757\n164 0.23024655878543854\n165 0.22194316983222961\n166 0.2139613926410675\n167 0.20628225803375244\n168 0.1988896280527115\n169 0.19178372621536255\n170 0.1849401742219925\n171 0.1783595234155655\n172 0.17201894521713257\n173 0.16592079401016235\n174 0.16004474461078644\n175 0.15438586473464966\n176 0.14894405007362366\n177 0.14370416104793549\n178 0.138652503490448\n179 0.13379229605197906\n180 0.12911604344844818\n181 0.12460853159427643\n182 0.12026216834783554\n183 0.11607621610164642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184 0.11204429715871811\n185 0.1081606075167656\n186 0.10443057119846344\n187 0.10083778947591782\n188 0.09737302362918854\n189 0.09403350204229355\n190 0.09081519395112991\n191 0.08771301805973053\n192 0.08472336828708649\n193 0.08184240758419037\n194 0.07906540483236313\n195 0.07638315856456757\n196 0.07379596680402756\n197 0.07130178809165955\n198 0.06889689713716507\n199 0.0665765032172203\n200 0.06433633714914322\n201 0.062174245715141296\n202 0.060087788850069046\n203 0.058075230568647385\n204 0.05613439902663231\n205 0.05426061898469925\n206 0.05245199427008629\n207 0.05070352181792259\n208 0.049014613032341\n209 0.04738475754857063\n210 0.04581179469823837\n211 0.044292669743299484\n212 0.042826637625694275\n213 0.04141179472208023\n214 0.04004340246319771\n215 0.03872080147266388\n216 0.03744499012827873\n217 0.036212678998708725\n218 0.03502224385738373\n219 0.03387215733528137\n220 0.03276090323925018\n221 0.03168760985136032\n222 0.03065052069723606\n223 0.02964845485985279\n224 0.02868006005883217\n225 0.027744634076952934\n226"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.026840535923838615\n227 0.025967078283429146\n228 0.025122886523604393\n229 0.02430645003914833\n230 0.023517467081546783\n231 0.022755064070224762\n232 0.02201823703944683\n233 0.02130584977567196\n234 0.020617468282580376\n235 0.019951455295085907\n236 0.019307784736156464\n237 0.018685176968574524\n238 0.018083451315760612\n239 0.017502009868621826\n240 0.016940155997872353\n241 0.016396062448620796\n242 0.015869854018092155\n243 0.015361095778644085\n244 0.01486889272928238\n245 0.014393371529877186\n246 0.013933544978499413\n247 0.01348894089460373\n248 0.013058710843324661\n249 0.012642358429729939\n250 0.012239662930369377\n251 0.011850505135953426\n252 0.011473827064037323\n253 0.011109454557299614\n254 0.010757523588836193\n255 0.010417192243039608\n256 0.010087837465107441\n257 0.009769300930202007\n258 0.00946107693016529\n259 0.009162983857095242\n260 0.008874624036252499\n261 0.008595616556704044\n262 0.00832541286945343\n263 0.008063891902565956\n264 0.007810890208929777\n265 0.007565944455564022\n266 0.007328806445002556\n267 0.007099216803908348\n268 0.006877251900732517\n269 0.006662146188318729\n270 0.006454010494053364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271 0.006252448074519634\n272 0.006057523190975189\n273 0.005868759471923113\n274 0.005685992538928986\n275 0.0055090500973165035\n276 0.005337761715054512\n277 0.005171921569854021\n278 0.005011180881410837\n279 0.00485572125762701\n280 0.004705128725618124\n281 0.004559242632240057\n282 0.004417982883751392\n283 0.004281147383153439\n284 0.004148662555962801\n285 0.004020474851131439\n286 0.0038962143007665873\n287 0.0037758329417556524\n288 0.0036593328695744276\n289 0.003546498715877533\n290 0.003437227103859186\n291 0.003331406507641077\n292 0.003228794550523162\n293 0.003129397053271532\n294 0.003033166518434882\n295 0.0029400039929896593\n296 0.0028497669845819473\n297 0.0027623078785836697\n298 0.002677562180906534\n299 0.002595496829599142\n300 0.0025159677024930716\n301 0.0024389231111854315\n302 0.002364339306950569\n303 0.0022919911425560713\n304 0.002221944509074092\n305 0.0021540315356105566\n306 0.0020882689859718084\n307 0.0020245627965778112\n308 0.0019628158770501614\n309 0.0019029799150303006\n310 0.0018449799390509725\n311 0.0017888309666886926\n312 0.001734385616146028\n313 0.0016816650750115514\n314 0.001630531856790185\n315 0.0015809877077117562\n316 0.0015330123715102673\n317 0.0014865141129121184\n318 0.0014414413599297404\n319"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0013977759517729282\n320 0.0013554098550230265\n321 0.0013143415562808514\n322 0.0012745594140142202\n323 0.0012359789106994867\n324 0.0011986165773123503\n325 0.0011623726459220052\n326 0.0011272558476775885\n327 0.0010932135628536344\n328 0.0010602041147649288\n329 0.001028232742100954\n330 0.0009972327388823032\n331 0.0009671919979155064\n332 0.0009380371775478125\n333 0.0009097818983718753\n334 0.0008824086980894208\n335 0.0008558655972592533\n336 0.0008301291964016855\n337 0.0008051948971115053\n338 0.0007809955859556794\n339 0.0007575501804240048\n340 0.0007348074577748775\n341 0.000712763168849051\n342 0.000691406661644578\n343 0.0006706918939016759\n344 0.0006506015779450536\n345 0.0006311338511295617\n346 0.000612228992395103\n347 0.0005939132533967495\n348 0.0005761703941971064\n349 0.0005589475040324032\n350 0.0005422489484772086\n351 0.0005260601174086332\n352 0.0005103569128550589\n353 0.0004951186128892004\n354 0.0004803645424544811\n355 0.0004660592239815742\n356 0.00045217384467832744\n357 0.0004387052031233907\n358 0.0004256361280567944\n359 0.0004129812296014279\n360 0.00040069560054689646\n361 0.0003887824423145503\n362 0.00037721407716162503\n363 0.0003660086658783257\n364 0.0003551434783730656\n365 0.0003446004702709615\n366 0.0003343813878018409\n367 0.0003244590770918876\n368 0.0003148360992781818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369 0.00030551207601092756\n370 0.00029645522590726614\n371 0.00028767346520908177\n372 0.0002791524166241288\n373 0.0002708989486563951\n374 0.00026288730441592634\n375 0.0002551107027102262\n376 0.00024757106439210474\n377 0.0002402552345301956\n378 0.00023316113220062107\n379 0.0002262741472804919\n380 0.00021960664889775217\n381 0.00021312304306775331\n382 0.00020683530601672828\n383 0.00020073671475984156\n384 0.00019482312200125307\n385 0.00018909916980192065\n386 0.00018353256746195257\n387 0.00017812426085583866\n388 0.0001728846546029672\n389 0.00016779638826847076\n390 0.00016286500613205135\n391 0.00015807422460056841\n392 0.00015343588893301785\n393 0.00014892756007611752\n394 0.00014455536438617855\n395 0.00014031652244739234\n396 0.00013620121171697974\n397 0.0001322085881838575\n398 0.00012832660286221653\n399 0.00012457012780942023\n400 0.00012091693497495726\n401 0.00011738034663721919\n402 0.00011394045577617362\n403 0.000110608983959537\n404 0.00010737040429376066\n405 0.00010422689229017124\n406 0.00010118162754224613\n407 9.822520223679021e-05\n408 9.535695426166058e-05\n409 9.257478086510673e-05\n410 8.987527689896524e-05\n411 8.724970393814147e-05\n412 8.47058036015369e-05\n413 8.22343718027696e-05\n414 7.983386603882536e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415 7.750792428851128e-05\n416 7.525052933488041e-05\n417 7.30587198631838e-05\n418 7.09342275513336e-05\n419 6.8870052928105e-05\n420 6.686767301289365e-05\n421 6.492088141385466e-05\n422 6.303354894043878e-05\n423 6.119993486208841e-05\n424 5.9423236962175e-05\n425 5.769103154307231e-05\n426 5.6018936447799206e-05\n427 5.439105007098988e-05\n428 5.281338235363364e-05\n429 5.1284201617818326e-05\n430 4.979592631570995e-05\n431 4.835336221731268e-05\n432 4.695059033110738e-05\n433 4.55911249446217e-05\n434 4.427333260537125e-05\n435 4.2991254304070026e-05\n436 4.1743831388885155e-05\n437 4.053709199069999e-05\n438 3.936191205866635e-05\n439 3.822651342488825e-05\n440 3.71188907593023e-05\n441 3.60477642971091e-05\n442 3.500633829389699e-05\n443 3.3996027923421934e-05\n444 3.3013129723258317e-05\n445 3.205849134246819e-05\n446 3.1133451557252556e-05\n447 3.0234008590923622e-05\n448 2.9364717192947865e-05\n449 2.8517833925434388e-05\n450 2.769497223198414e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451 2.689686880330555e-05\n452 2.6122106646653265e-05\n453 2.536994725232944e-05\n454 2.463812052155845e-05\n455 2.3929342205519788e-05\n456 2.3240465452545322e-05\n457 2.2572472516912967e-05\n458 2.1923671738477424e-05\n459 2.129374297510367e-05\n460 2.068071080429945e-05\n461 2.008645242312923e-05\n462 1.951213380380068e-05\n463 1.8951621314045042e-05\n464 1.840844015532639e-05\n465 1.787701330613345e-05\n466 1.7363945516990498e-05\n467 1.68656279129209e-05\n468 1.6382686226279475e-05\n469 1.5912075468804687e-05\n470 1.545789018564392e-05\n471 1.5013904885563534e-05\n472 1.4583089978259522e-05\n473 1.4166746950650122e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474 1.3760417459707242e-05\n475 1.3367769497563131e-05\n476 1.2983890883333515e-05\n477 1.2612815226020757e-05\n478 1.2250615327502601e-05\n479 1.1902359801752027e-05\n480 1.1562456165847834e-05\n481 1.123201673181029e-05\n482 1.0911580829997547e-05\n483 1.0599647794151679e-05\n484 1.0297583685314748e-05\n485 1.0001687769545242e-05\n486 9.71776717051398e-06\n487 9.43941358855227e-06\n488 9.17100715014385e-06\n489 8.909194548323285e-06\n490 8.655086276121438e-06\n491 8.408808753301855e-06\n492 8.16943429526873e-06\n493 7.935988833196461e-06\n494 7.711094440310262e-06\n495 7.491565156669822e-06\n496 7.2781022026902065e-06\n497 7.070147148624528e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498 6.86928660798003e-06\n499 6.673463758488651e-06\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs, and wrap them in Variables\n",
    "x = Variable(torch.randn(N, D_in))\n",
    "y = Variable(torch.randn(N, D_out), requires_grad=False)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = TwoLayerNet(D_in, H, D_out)\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "for t in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(t, loss.data[0])\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch:Control Flow+Weight Sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 579.2811889648438\n1 626.1478881835938\n2 578.4542236328125\n3 573.5377197265625\n4 444.7187805175781\n5 553.1307373046875\n6 545.5696411132812\n7 567.9146728515625\n8 565.945068359375\n9 515.352783203125\n10 559.9873046875\n11 227.67984008789062\n12 479.2967529296875\n13 565.5686645507812\n14 564.0177001953125\n15 537.7070922851562\n16 418.8270568847656\n17 144.58738708496094\n18 125.71770477294922\n19 507.350830078125\n20 86.72093963623047\n21 540.25732421875\n22 533.533203125\n23 307.33697509765625\n24"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 512.2589111328125\n25 266.5473327636719\n26 238.8343963623047\n27 206.75918579101562\n28 357.727294921875\n29 120.2656021118164\n30 399.1911315917969\n31 136.48684692382812\n32 257.1131591796875\n33 302.4517822265625\n34 267.9374084472656\n35 155.5503387451172\n36 131.9306182861328\n37 119.21885681152344\n38 93.39094543457031\n39 72.18513488769531\n40 137.09756469726562\n41 160.26535034179688\n42 62.92022705078125\n43 66.11343383789062\n44 159.94125366210938\n45 130.67047119140625\n46 160.38433837890625\n47 127.58135986328125\n48 64.76856994628906\n49 217.23919677734375\n50 75.60490417480469\n51 79.6137466430664\n52 112.07012939453125\n53 46.23508834838867\n54 30.906429290771484\n55 118.34403991699219\n56 76.6913070678711\n57 95.38005065917969\n58 160.8048095703125\n59 69.64665985107422\n60 42.38676071166992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 27.834890365600586\n62 50.514583587646484\n63 68.42131805419922\n64 169.60693359375\n65 25.30270767211914\n66 69.8674087524414\n67 47.414154052734375\n68 33.40186309814453\n69 70.80652618408203\n70 55.219425201416016\n71 92.26636505126953\n72 18.448530197143555\n73 16.765647888183594\n74 26.86956024169922\n75 25.518579483032227\n76 30.169666290283203\n77 48.08154296875\n78 29.271909713745117\n79 42.0146598815918\n80 21.0435733795166\n81 15.29680061340332\n82 12.257014274597168\n83 22.114900588989258\n84 18.493629455566406\n85 12.114619255065918\n86 13.824557304382324\n87 16.73895835876465\n88 10.95552921295166\n89 26.92206382751465\n90 8.629441261291504\n91 11.736943244934082\n92 13.85471248626709\n93 11.123369216918945\n94 9.43989372253418\n95 7.172213554382324\n96 5.39292573928833\n97 26.92165756225586\n98 6.44054651260376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 7.7308149337768555\n100 5.59895133972168\n101 13.925386428833008\n102 9.137762069702148\n103 4.393202781677246\n104 7.541062831878662\n105 9.823338508605957\n106 8.184504508972168\n107 3.8542516231536865\n108 16.850563049316406\n109 3.7725067138671875\n110 4.61052131652832\n111 6.743797779083252\n112 4.766298770904541\n113 16.61309051513672\n114 3.0946707725524902\n115 7.812511444091797\n116 8.520451545715332\n117 6.699038982391357\n118 5.0098137855529785\n119 5.485474586486816\n120 6.249294757843018\n121 6.384918212890625\n122 5.9231672286987305\n123 5.069785118103027\n124 4.055372714996338\n125 3.2584245204925537\n126 5.37659215927124\n127 3.931001663208008\n128 3.9491491317749023\n129 2.8136181831359863\n130 8.289978981018066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 4.359673976898193\n132 3.7932846546173096\n133 5.229251861572266\n134 2.509073257446289\n135 3.1682794094085693\n136 1.399181842803955\n137 6.632429599761963\n138 2.7122812271118164\n139 5.494428634643555\n140 2.726137638092041\n141 4.435812473297119\n142 1.6769516468048096\n143 2.032855272293091\n144 1.7878484725952148\n145 2.94062876701355\n146 1.447433590888977\n147 4.598245620727539\n148 2.86721134185791\n149 3.547065258026123\n150 3.3331241607666016\n151 2.6372103691101074\n152 2.8235390186309814\n153 3.222302198410034\n154 1.8947850465774536\n155 1.3021609783172607\n156 2.3542044162750244\n157 4.567323684692383\n158 2.338239908218384\n159 2.3894879817962646\n160 1.3744500875473022\n161 4.333655834197998\n162 2.8707900047302246\n163 2.2850348949432373\n164 1.9210381507873535\n165 1.9897133111953735\n166 1.8782628774642944\n167 2.210524797439575\n168 0.6655783653259277\n169 2.15700364112854\n170 1.3478074073791504\n171 1.9660007953643799\n172 3.6310198307037354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173 3.606325387954712\n174 2.070807695388794\n175 1.2058366537094116\n176 9.452210426330566\n177 4.451322078704834\n178 2.979980707168579\n179 6.934516906738281\n180 3.6616933345794678\n181 2.0528531074523926\n182 1.5695405006408691\n183 2.2580974102020264\n184 1.6153889894485474\n185 2.532259225845337\n186 5.305485725402832\n187 1.5855216979980469\n188 0.7446862459182739\n189 0.5088422894477844\n190 30.992467880249023\n191 1.781816840171814\n192 1.193631649017334\n193 27.835451126098633\n194 5.680366039276123\n195 1.7219533920288086\n196 2.454378604888916\n197 3.6232168674468994\n198 5.643235206604004\n199 15.743963241577148\n200 4.43095064163208\n201 11.387221336364746\n202 2.4167752265930176\n203 1.0984454154968262\n204 0.8937978148460388\n205 8.487617492675781\n206 64.19110870361328\n207 3.665691375732422\n208 19.04189109802246\n209 30.660274505615234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 71.6889877319336\n211 6.682538986206055\n212 12.499897956848145\n213 21.721118927001953\n214 62.637664794921875\n215 70.63782501220703\n216 48.12139129638672\n217 18.378015518188477\n218 5.421093463897705\n219 9.011348724365234\n220 19.86536407470703\n221 38.60781478881836\n222 39.93772888183594\n223 17.249401092529297\n224 12.581512451171875\n225 10.218618392944336\n226 51.44794845581055\n227 10.476153373718262\n228 8.110448837280273\n229 3.3198792934417725\n230 6.263049125671387\n231 40.871212005615234\n232 5.5120134353637695\n233 14.248174667358398\n234 5.847199440002441\n235 8.908638000488281\n236 15.585082054138184\n237 11.544381141662598\n238 4.460543632507324\n239 6.060149192810059\n240 6.34747314453125\n241 5.017299652099609\n242 13.101153373718262\n243 1.951162338256836\n244 2.84648060798645\n245 2.6117641925811768\n246 3.3014285564422607\n247 5.520618438720703\n248 9.90561580657959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249 1.3610793352127075\n250 6.050148963928223\n251 3.809075355529785\n252 3.7430970668792725\n253 5.902588367462158\n254 1.3955708742141724\n255 1.3212463855743408\n256 7.490620136260986\n257 4.7211079597473145\n258 1.2112643718719482\n259 1.602180004119873\n260 1.6726640462875366\n261 3.461742401123047\n262 10.415332794189453\n263 1.0227941274642944\n264 1.11165189743042\n265 2.814704179763794\n266 1.9997109174728394\n267 3.078127145767212\n268 4.103938102722168\n269 1.233744502067566\n270 2.3635361194610596\n271 1.3709654808044434\n272 0.9615188241004944\n273 0.7388182282447815\n274 0.633364737033844\n275 1.0744372606277466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276 7.251340389251709\n277 0.689713180065155\n278 1.1731141805648804\n279 1.466992974281311\n280 0.4524526298046112\n281 3.684954881668091\n282 5.112452030181885\n283 0.8519327044487\n284 2.610372304916382\n285 1.960906982421875\n286 3.9472079277038574\n287 1.3821748495101929\n288 2.509199857711792\n289 2.3054890632629395\n290 2.933450937271118\n291 2.6946752071380615\n292 1.1134600639343262\n293 0.9166306853294373\n294 1.3269670009613037\n295 1.137163758277893\n296 4.302125930786133\n297 3.021597146987915\n298 0.9808274507522583\n299 1.4822721481323242\n300 5.154778957366943\n301 3.9114737510681152\n302 2.2908935546875\n303 2.4096946716308594\n304 0.9477596282958984\n305 0.3126436471939087\n306 0.41029971837997437\n307 13.091256141662598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308 2.886639356613159\n309 1.079790472984314\n310 1.2135614156723022\n311 1.4371185302734375\n312 2.173128843307495\n313 2.1874310970306396\n314 5.3754377365112305\n315 4.476874828338623\n316 1.2078717947006226\n317 1.0890096426010132\n318 3.426506519317627\n319 6.676770210266113\n320 3.531709909439087\n321 3.7241694927215576\n322 0.9838452935218811\n323 0.4102412462234497\n324 0.30380135774612427\n325 5.085175037384033\n326 1.039337158203125\n327 6.885281562805176\n328 4.15075159072876\n329 0.5840387940406799\n330 2.0528335571289062\n331 15.175241470336914\n332 7.616365909576416\n333 0.788946270942688\n334 2.217226028442383\n335 11.62334156036377\n336 17.72265625\n337 1.1581716537475586\n338 2.924036979675293\n339 4.179074287414551\n340 19.629867553710938\n341 1.7118093967437744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342 0.8021994829177856\n343 1.370688796043396\n344 1.4180055856704712\n345 2.1138880252838135\n346 5.456854343414307\n347 1.3304660320281982\n348 2.0939667224884033\n349 4.767201900482178\n350 4.07631254196167\n351 2.7968380451202393\n352 3.1644608974456787\n353 2.510474443435669\n354 1.7294639348983765\n355 1.9281656742095947\n356 1.6978381872177124\n357 1.6519039869308472\n358 1.4058774709701538\n359 1.5162339210510254\n360 2.4905409812927246\n361 1.9835187196731567\n362 1.1356563568115234\n363 3.1655120849609375\n364 2.330571174621582\n365 1.1396987438201904\n366 0.7311448454856873\n367 3.099646806716919\n368 2.0975844860076904\n369 0.9749060869216919\n370 0.9975135922431946\n371 4.164550304412842\n372 0.5537139177322388\n373 0.6225274205207825\n374 2.7129640579223633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375 0.7921269536018372\n376 1.0521328449249268\n377 1.1206196546554565\n378 1.0361659526824951\n379 1.6904116868972778\n380 1.200163722038269\n381 0.6384315490722656\n382 1.3227614164352417\n383 1.3423291444778442\n384 0.8400467038154602\n385 0.6128174066543579\n386 0.35213983058929443\n387 0.940692126750946\n388 2.3396201133728027\n389 1.0833040475845337\n390 1.0733064413070679\n391 0.6937381029129028\n392 2.082360029220581\n393 1.6953420639038086\n394 0.8464126586914062\n395 0.3026584982872009\n396 0.5421423316001892\n397 1.0486948490142822\n398 2.770493984222412\n399 0.8438870310783386\n400 0.43924087285995483\n401 0.7086920142173767\n402 3.4759345054626465\n403 0.12843090295791626\n404 0.14768974483013153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405 0.3257993459701538\n406 0.3419460952281952\n407 1.1292579174041748\n408 0.7222411632537842\n409 0.2689935266971588\n410 0.2215707004070282\n411 1.1080650091171265\n412 0.6511936783790588\n413 0.7122313976287842\n414 0.07649759948253632\n415 0.9295676350593567\n416 0.6338801383972168\n417 0.07307782769203186\n418 0.6313402652740479\n419 0.08844128996133804\n420 0.5356501936912537\n421 0.633928120136261\n422 0.6141961216926575\n423 0.44715625047683716\n424 0.46995604038238525\n425 0.47558099031448364\n426 0.1152191162109375\n427 0.8754890561103821\n428 0.06872635334730148\n429 0.6133474111557007\n430 0.3885127305984497\n431 0.07618509978055954\n432 0.42085811495780945"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n433 0.05563460662961006\n434 0.3486926555633545\n435 0.31393012404441833\n436 0.6237581372261047\n437 0.33002787828445435\n438 0.08598588407039642\n439 0.08657770603895187\n440 0.5412977933883667\n441 0.6868314743041992\n442 0.041855163872241974\n443 0.38312020897865295\n444 0.6607681512832642\n445 0.4929490089416504\n446 0.6407787203788757\n447 0.3860333561897278\n448 1.0182002782821655\n449 0.6658596396446228\n450 0.3059709072113037\n451 0.5157551169395447\n452 0.04723919928073883\n453 0.04972841963171959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454 0.9184428453445435\n455 1.5519593954086304\n456 0.5323017239570618\n457 1.7348862886428833\n458 0.5546625852584839\n459 0.3728911876678467\n460 0.8290777206420898\n461 0.39089927077293396\n462 0.10096853226423264\n463 0.6841334104537964\n464 3.3644890785217285\n465 0.38640540838241577\n466 1.1137409210205078\n467 0.8874310255050659\n468 3.4766151905059814\n469 0.20147879421710968\n470 1.8553760051727295\n471 0.9170066714286804\n472 1.3277828693389893\n473 0.428376168012619\n474 1.2176682949066162\n475 0.06021641194820404\n476 0.659574031829834\n477 2.006288766860962\n478 0.1487860232591629\n479 0.5808916687965393\n480 0.340841680765152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481 2.9642670154571533\n482 0.8363550901412964\n483 1.0237972736358643\n484 2.1743791103363037\n485 0.6269259452819824\n486 0.13133420050144196\n487 1.265522837638855\n488 1.4707155227661133\n489 0.44298356771469116\n490 1.031378984451294\n491 0.7031746506690979\n492 0.9203046560287476\n493 0.4302186667919159\n494 0.26981469988822937\n495 0.1333446502685547\n496 0.09987708926200867\n497 2.2104275226593018\n498 0.3609093129634857\n499 0.7659124732017517\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import random\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class DynamicNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we construct three nn.Linear instances that we will use\n",
    "        in the forward pass.\n",
    "        \"\"\"\n",
    "        super(DynamicNet, self).__init__()\n",
    "        self.input_linear = torch.nn.Linear(D_in, H)\n",
    "        self.middle_linear = torch.nn.Linear(H, H)\n",
    "        self.output_linear = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        For the forward pass of the model, we randomly choose either 0, 1, 2, or 3\n",
    "        and reuse the middle_linear Module that many times to compute hidden layer\n",
    "        representations.\n",
    "\n",
    "        Since each forward pass builds a dynamic computation graph, we can use normal\n",
    "        Python control-flow operators like loops or conditional statements when\n",
    "        defining the forward pass of the model.\n",
    "\n",
    "        Here we also see that it is perfectly safe to reuse the same Module many\n",
    "        times when defining a computational graph. This is a big improvement from Lua\n",
    "        Torch, where each Module could be used only once.\n",
    "        \"\"\"\n",
    "        h_relu = self.input_linear(x).clamp(min=0)\n",
    "        for _ in range(random.randint(0, 3)):\n",
    "            h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
    "        y_pred = self.output_linear(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs, and wrap them in Variables\n",
    "x = Variable(torch.randn(N, D_in))\n",
    "y = Variable(torch.randn(N, D_out), requires_grad=False)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = DynamicNet(D_in, H, D_out)\n",
    "\n",
    "# Construct our loss function and an Optimizer. Training this strange model with\n",
    "# vanilla stochastic gradient descent is tough, so we use momentum\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "for t in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(t, loss.data[0])\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
